{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Food Facts Course Project - Cleaning, manipulating and visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's import usefull libraries for the project and make matplolib displaying graphs inline the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path # For filepath manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step will be to load the Open Food Facts CSV file, which in fact is a TSV file (Cells are separated with tabs).\n",
    "Loading this file will take a consequent amount of time, as the file is 1Gb big. First thing to do will be to perform some cleanup and removal of useless data, and save the result as a new CSV file.\n",
    "\n",
    "This new CSV file will be used as datasource in this Notebook using the first **MAX_ENTRY_TO_LOAD** rows while coding.\n",
    "\n",
    "**Don't forget to set MAX_ENTRY_TO_LOAD = None when coding is finished.** Otherwise, only a subset of the data will be processed.\n",
    "\n",
    "* Note that this Notebook checks if the cleaned Datafile exists and create it otherwise. This process relies on three functions: First one will load the original TSV file, the second one will cleanup the orignal data and the third one will dump the cleand data into a new CSV file.\n",
    "\n",
    "The following global constant can be adapted to suit your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename of the original TSV file\n",
    "ORIGINAL_TSV_FILENAME = path.join('data','OpenFoodFacts.tsv')\n",
    "\n",
    "# Filename of the cleaned data build in this Notebook\n",
    "CLEANED_CSV_FILENAME = path.join('data','OpenFoodFacts-cleaned.csv')\n",
    "\n",
    "# If set to true, the original data file loading process is forced, event if the\n",
    "# cleaned CSV file exists. Should be set to **True** when coding is finished\n",
    "FORCE_LOAD_ORIGINAL_FILE = False # PRoduction value = True\n",
    "\n",
    "# Maximum NaN percentage accepted in a column. If above, the column is dropped.\n",
    "MAX_NAN_PERCENT_VALUE = 80\n",
    "\n",
    "# Number of rows loaded from cleaned CSV file. Usefull while coding, this value should be\n",
    "# set ton **None** when coding is finished.\n",
    "MAX_ENTRY_TO_LOAD = 20000 # Production value = None\n",
    "\n",
    "# List of columns that will be removed from the Dataset (useless one)\n",
    "COLUMNS_TO_DROP = [\n",
    "    'creator', 'brands', 'brands_tags', 'categories','main_category', 'countries',\n",
    "    'countries_tags', 'additives', 'additives_tags', 'categories_tags', 'states',\n",
    "    'states_en', 'states_tags', 'url', 'quantity', 'packaging_tags', 'packaging',\n",
    "    'created_t', 'last_modified_t', 'pnns_groups_1', 'pnns_groups_2', 'image_url',\n",
    "    'image_small_url', 'code'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A. Importing and cleaning the data\n",
    "\n",
    "Importing the datasource is done using Pandas **read_csv** method, using parameter **sep=\"\\t\"** as the content of the file is a tabulation spearated CSV file.\n",
    "\n",
    "* Note that I've set the **low_memory** option to False in order to avoid warnings when loading the file. Number of columns is quite important and the process to determine the column dtype is too consuming*\n",
    "\n",
    "\n",
    "### Some function definitions\n",
    "\n",
    "#### Data loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOriginalTsvFile(filename):\n",
    "    print(\"Loading data from file\",ORIGINAL_TSV_FILENAME)\n",
    "    print(\"Please wait...\")\n",
    "    df = pd.read_csv(ORIGINAL_TSV_FILENAME,sep=\"\\t\",low_memory=False)\n",
    "    print(\"Loading process terminated.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to dump the cleaned data into a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpCleanedCsvFile(df,filename):\n",
    "    print(\"Dumping the cleaned Dataframe into file\",CLEANED_CSV_FILENAME)\n",
    "    print(\"Please wait...\")\n",
    "    df.to_csv(CLEANED_CSV_FILENAME)\n",
    "    print(\"Dumping process terminated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup function that process the Dataframe returned by the **loadOriginalTsvFile()** function\n",
    "\n",
    "This function will perform cleanup actions on the whole dataset. Further in this Notebook, more cleaning actions will come while we discover the content of the Open Food Facts database.\n",
    "\n",
    "Here is a list of the cleaning actions done here:\n",
    "\n",
    "* Drop unused column defined in the global parameter COLUMNS_TO_DROP\n",
    "* Drop columns where the percentage of null values is above MAX_NAN_PERCENT_VALUE\n",
    "* Drop rows where **product_name** or **countries_en** column are empty\n",
    "* Drop rows with duplicates in 'product_name' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOriginalData(df):\n",
    "\n",
    "    print(\"Cleaning the dataframe\")\n",
    "    print(\"Please wait...\")\n",
    "    # Drop unused columns\n",
    "    df.drop(COLUMNS_TO_DROP,axis = 1,inplace=True)\n",
    "    \n",
    "    # Drop columns where percentage of NaN values is too high\n",
    "    df = df.dropna(axis=1, thresh= len(df)*(1 - MAX_NAN_PERCENT_VALUE / 100), how='all') \n",
    "    \n",
    "    # Drop rows with empty product_name or countries_en\n",
    "    df = df[np.logical_and(\n",
    "        np.logical_not(df['product_name'].isnull()),\n",
    "        np.logical_not(df['countries_en'].isnull())\n",
    "    )]\n",
    "    \n",
    "    # Drop duplicated rows in column product_name\n",
    "    df.drop_duplicates(subset=['product_name'],inplace=True)\n",
    "\n",
    "    print(\"Cleaning process terminated\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading process\n",
    "\n",
    "Now that our loading functions are defined, put some logic here to avoid long time processing while coding.\n",
    "\n",
    "**Do not forget to set the global constant to Production values when coding is finished**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/OpenFoodFacts.tsv\n",
      "Please wait...\n",
      "Loading process terminated.\n",
      "Cleaning the dataframe\n",
      "Please wait...\n",
      "Cleaning process terminated\n",
      "Dumping the cleaned Dataframe into file data/OpenFoodFacts-cleaned.csv\n",
      "Please wait...\n",
      "Dumping process terminated\n",
      "Loading the first 20000 rows from  data/OpenFoodFacts-cleaned.csv\n",
      "Please wait...\n",
      "Dataframe loaded\n",
      "Number of rows   : 20000\n",
      "Number of columns: 30\n"
     ]
    }
   ],
   "source": [
    "if (FORCE_LOAD_ORIGINAL_FILE == True) or path.exists(CLEANED_CSV_FILENAME) == False:\n",
    "    df = loadOriginalTsvFile(ORIGINAL_TSV_FILENAME)\n",
    "    df = cleanOriginalData(df)\n",
    "    dumpCleanedCsvFile(df, CLEANED_CSV_FILENAME)\n",
    "else:\n",
    "    print(\"Cleaned CSV file found. Original data file processing is skipped\")\n",
    "\n",
    "    \n",
    "if MAX_ENTRY_TO_LOAD != None:\n",
    "    print(\"Loading the first\",MAX_ENTRY_TO_LOAD,\"rows from \",CLEANED_CSV_FILENAME)\n",
    "else:\n",
    "    print(\"Loading data from \",CLEANED_CSV_FILENAME)\n",
    "\n",
    "print(\"Please wait...\")\n",
    "df = pd.read_csv(CLEANED_CSV_FILENAME,low_memory=False, nrows=MAX_ENTRY_TO_LOAD, index_col=0)\n",
    "print(\"Dataframe loaded\")\n",
    "\n",
    "print('Number of rows   :',format(df.shape[0]))\n",
    "print('Number of columns:',format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning process\n",
    "\n",
    "Now the we've loaded a *partially* cleaned dataframe, let's explore it and perform some more clean up.\n",
    "\n",
    "First, we can ensure that we do not have any duplicated lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated lines: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicated lines:\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that we do not have duplicated values in the **product_name** columns and set it as Dataframe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no duplicated values in 'product_name' column. Set it as Dataframe index\n"
     ]
    }
   ],
   "source": [
    "if 'product_name' in df.columns:\n",
    "    if df['product_name'].duplicated().sum() == 0:\n",
    "        print(\"There is no duplicated values in 'product_name' column. Set it as Dataframe index\")\n",
    "        df.set_index('product_name', inplace=True)\n",
    "    else:\n",
    "        print(\"WARNING: Duplicated values detected in 'product_name' column. Aborting Notebook.\")\n",
    "        exit(1)\n",
    "else:\n",
    "    print(\"Dataframe already indexed by 'product_name'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date and time columns into DateTime Pandas object, for smarter time manipulations.\n",
    "\n",
    "During the first **to_datetime()** run, I've found values that was not convertible to a Datetime object. For example, one of the row contains value **Dia,Sogeres** in its **created_datetime** cell. Solution is to set the *unparsable* datetime strings to NaT using **error=coerce** paramter in **to_datetime()** call, and then fill NaT value with **fillna()** function using **ffill** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_datetime'] = pd.to_datetime(df['created_datetime'], format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n",
    "df['created_datetime'].fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "df['last_modified_datetime'] = pd.to_datetime(df['last_modified_datetime'], format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n",
    "df['last_modified_datetime'].fillna(method = 'ffill', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additives_n</th>\n",
       "      <th>ingredients_from_palm_oil_n</th>\n",
       "      <th>ingredients_that_may_be_from_palm_oil_n</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19438.000000</td>\n",
       "      <td>19438.000000</td>\n",
       "      <td>19438.000000</td>\n",
       "      <td>19484.000000</td>\n",
       "      <td>19387.000000</td>\n",
       "      <td>16613.000000</td>\n",
       "      <td>16013.000000</td>\n",
       "      <td>16066.000000</td>\n",
       "      <td>19397.000000</td>\n",
       "      <td>18158.000000</td>\n",
       "      <td>16161.000000</td>\n",
       "      <td>19412.000000</td>\n",
       "      <td>19341.000000</td>\n",
       "      <td>19341.000000</td>\n",
       "      <td>15398.000000</td>\n",
       "      <td>15613.000000</td>\n",
       "      <td>15553.000000</td>\n",
       "      <td>15786.000000</td>\n",
       "      <td>15958.000000</td>\n",
       "      <td>15958.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.342474</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>1138.608086</td>\n",
       "      <td>12.181831</td>\n",
       "      <td>4.968698</td>\n",
       "      <td>0.112226</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>34.118356</td>\n",
       "      <td>16.866910</td>\n",
       "      <td>2.636399</td>\n",
       "      <td>6.989111</td>\n",
       "      <td>1.978487</td>\n",
       "      <td>0.778931</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.129003</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>9.750533</td>\n",
       "      <td>9.719326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.849387</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>0.191105</td>\n",
       "      <td>784.983821</td>\n",
       "      <td>16.564434</td>\n",
       "      <td>7.560172</td>\n",
       "      <td>3.146284</td>\n",
       "      <td>0.038303</td>\n",
       "      <td>29.656419</td>\n",
       "      <td>21.553938</td>\n",
       "      <td>4.220313</td>\n",
       "      <td>8.492355</td>\n",
       "      <td>11.820749</td>\n",
       "      <td>4.653824</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.310653</td>\n",
       "      <td>4.195635</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>9.193572</td>\n",
       "      <td>9.204193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>-6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.620000</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>0.683260</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>61.900000</td>\n",
       "      <td>26.670000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.541780</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10757.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>92.860000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>870.856780</td>\n",
       "      <td>342.857000</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>35.714300</td>\n",
       "      <td>522.727000</td>\n",
       "      <td>12.121210</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        additives_n  ingredients_from_palm_oil_n  \\\n",
       "count  19438.000000                 19438.000000   \n",
       "mean       2.342474                     0.000875   \n",
       "std        2.849387                     0.029561   \n",
       "min        0.000000                     0.000000   \n",
       "25%        0.000000                     0.000000   \n",
       "50%        2.000000                     0.000000   \n",
       "75%        3.000000                     0.000000   \n",
       "max       29.000000                     1.000000   \n",
       "\n",
       "       ingredients_that_may_be_from_palm_oil_n   energy_100g      fat_100g  \\\n",
       "count                             19438.000000  19484.000000  19387.000000   \n",
       "mean                                  0.035960   1138.608086     12.181831   \n",
       "std                                   0.191105    784.983821     16.564434   \n",
       "min                                   0.000000      0.000000      0.000000   \n",
       "25%                                   0.000000    393.000000      0.000000   \n",
       "50%                                   0.000000   1180.000000      4.760000   \n",
       "75%                                   0.000000   1674.000000     20.000000   \n",
       "max                                   3.000000  10757.000000    100.000000   \n",
       "\n",
       "       saturated-fat_100g  trans-fat_100g  cholesterol_100g  \\\n",
       "count        16613.000000    16013.000000      16066.000000   \n",
       "mean             4.968698        0.112226          0.019907   \n",
       "std              7.560172        3.146284          0.038303   \n",
       "min              0.000000       -3.030000          0.000000   \n",
       "25%              0.000000        0.000000          0.000000   \n",
       "50%              1.820000        0.000000          0.000000   \n",
       "75%              7.140000        0.000000          0.026000   \n",
       "max             92.860000      369.000000          0.900000   \n",
       "\n",
       "       carbohydrates_100g   sugars_100g    fiber_100g  proteins_100g  \\\n",
       "count        19397.000000  18158.000000  16161.000000   19412.000000   \n",
       "mean            34.118356     16.866910      2.636399       6.989111   \n",
       "std             29.656419     21.553938      4.220313       8.492355   \n",
       "min              0.000000     -1.200000     -6.700000       0.000000   \n",
       "25%              6.670000      1.690000      0.000000       0.000000   \n",
       "50%             24.620000      6.670000      1.500000       4.410000   \n",
       "75%             61.900000     26.670000      3.600000      10.000000   \n",
       "max            100.000000    100.000000    100.000000     100.000000   \n",
       "\n",
       "          salt_100g   sodium_100g  vitamin-a_100g  vitamin-c_100g  \\\n",
       "count  19341.000000  19341.000000    15398.000000    15613.000000   \n",
       "mean       1.978487      0.778931        0.000155        0.010478   \n",
       "std       11.820749      4.653824        0.000766        0.310653   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        0.076200      0.030000        0.000000        0.000000   \n",
       "50%        0.683260      0.269000        0.000000        0.000000   \n",
       "75%        1.541780      0.607000        0.000107        0.002800   \n",
       "max      870.856780    342.857000        0.050700       35.714300   \n",
       "\n",
       "       calcium_100g     iron_100g  nutrition-score-fr_100g  \\\n",
       "count  15553.000000  15786.000000             15958.000000   \n",
       "mean       0.129003      0.003263                 9.750533   \n",
       "std        4.195635      0.119152                 9.193572   \n",
       "min        0.000000      0.000000               -10.000000   \n",
       "25%        0.000000      0.000000                 1.000000   \n",
       "50%        0.033000      0.000950                11.000000   \n",
       "75%        0.101000      0.002250                17.000000   \n",
       "max      522.727000     12.121210                35.000000   \n",
       "\n",
       "       nutrition-score-uk_100g  \n",
       "count             15958.000000  \n",
       "mean                  9.719326  \n",
       "std                   9.204193  \n",
       "min                 -10.000000  \n",
       "25%                   1.000000  \n",
       "50%                  11.000000  \n",
       "75%                  17.000000  \n",
       "max                  35.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

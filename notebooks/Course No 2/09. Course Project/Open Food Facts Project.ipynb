{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Food Facts Course Project - Cleaning, manipulating and visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's import usefull libraries for the project and make matplolib displaying graphs inline the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path # For filepath manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step will be to load the Open Food Facts CSV file, which in fact is a TSV file (Cells are separated with tabs).\n",
    "Loading this file will take a consequent amount of time, as the file is 1Gb big. First thing to do will be to perform some cleanup and removal of useless data, and save the result as a new CSV file.\n",
    "\n",
    "This new CSV file will be used as datasource in this Notebook using the first **MAX_ENTRY_TO_LOAD** rows while coding.\n",
    "\n",
    "**Don't forget to set MAX_ENTRY_TO_LOAD = None when coding is finished.** Otherwise, only a subset of the data will be processed.\n",
    "\n",
    "* Note that this Notebook checks if the cleaned Datafile exists and create it otherwise. This process relies on three functions: First one will load the original TSV file, the second one will cleanup the orignal data and the third one will dump the cleand data into a new CSV file.\n",
    "\n",
    "The following global constant can be adapted to suit your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename of the original TSV file\n",
    "ORIGINAL_TSV_FILENAME = path.join('data','OpenFoodFacts.tsv')\n",
    "\n",
    "# Filename of the cleaned data build in this Notebook\n",
    "CLEANED_CSV_FILENAME = path.join('data','OpenFoodFacts-cleaned.csv')\n",
    "\n",
    "# If set to true, the original data file loading process is forced, event if the\n",
    "# cleaned CSV file exists. Should be set to **True** when coding is finished\n",
    "FORCE_LOAD_ORIGINAL_FILE = False\n",
    "\n",
    "# Maximum NaN percentage accepted in a column. If above, the column is dropped.\n",
    "MAX_NAN_PERCENT_VALUE = 0.4\n",
    "\n",
    "# Number of rows loaded from cleaned CSV file. Usefull while coding, this value should be\n",
    "# set ton **None** when coding is finished.\n",
    "MAX_ENTRY_TO_LOAD = 10000\n",
    "\n",
    "# List of columns that will be removed from the Dataset (useless one)\n",
    "COLUMNS_TO_DROP = [\n",
    "    'creator', 'brands', 'brands_tags', 'categories','main_category', 'countries',\n",
    "    'countries_tags', 'additives', 'additives_tags', 'categories_tags', 'states',\n",
    "    'states_en', 'states_tags', 'url', 'quantity', 'packaging_tags', 'packaging',\n",
    "    'created_t', 'last_modified_t', 'pnns_groups_1', 'pnns_groups_2', 'image_url',\n",
    "    'image_small_url'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A. Importing and cleaning the data\n",
    "\n",
    "Importing the datasource is done using Pandas **read_csv** method, using parameter **sep=\"\\t\"** as the content of the file is a tabulation spearated CSV file.\n",
    "\n",
    "* Note that I've set the **low_memory** option to False in order to avoid warnings when loading the file. Number of columns is quite important and the process to determine the column dtype is too consuming*\n",
    "\n",
    "\n",
    "### Some function definitions\n",
    "\n",
    "#### Data loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOriginalTsvFile(filename):\n",
    "    print(\"Loading data from file\",ORIGINAL_TSV_FILENAME)\n",
    "    print(\"Please wait...\")\n",
    "    df = pd.read_csv(ORIGINAL_TSV_FILENAME,sep=\"\\t\",low_memory=False)\n",
    "    print(\"Loading process terminated.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to dump the cleaned data into a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpCleanedCsvFile(df,filename):\n",
    "    print(\"Dumping the cleaned Dataframe into file\",CLEANED_CSV_FILENAME)\n",
    "    print(\"Please wait...\")\n",
    "    df.to_csv(CLEANED_CSV_FILENAME)\n",
    "    print(\"Dumping process terminated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup function that process the Dataframe returned by the **loadOriginalTsvFile()** function\n",
    "\n",
    "* Note: This function modifies the Dataframe received as parameter (using inplace = True when suitable)\n",
    "\n",
    "This function will perform cleanup actions on the whole dataset. Further in this Notebook, more cleaning actions will come while we discover the content of the Open Food Facts database.\n",
    "\n",
    "Here is a list of the cleaning actions done here:\n",
    "\n",
    "* Drop unused column defined in the global parameter COLUMNS_TO_DROP\n",
    "* Drop columns where the percentage of null values is above MAX_NAN_PERCENT_VALUE\n",
    "* Drop rows where **product_name** or **countries_en** column are empty\n",
    "* Drop rows with duplicates in 'product_name' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOriginalData(df):\n",
    "\n",
    "    print(\"Cleaning the dataframe)\n",
    "    print(\"Please wait...\")\n",
    "    # Drop unused columns\n",
    "    df.drop(COLUMNS_TO_DROP,axis = 1,inplace=True)\n",
    "    \n",
    "    # Drop columns where percentage of NaN values is too high\n",
    "    df = df.loc[:, (df.isnull().mean(axis=0) < MAX_NAN_PERCENT_VALUE)]\n",
    "    \n",
    "    # Drop rows with empty product_name or countries_en\n",
    "    df = df[np.logical_and(\n",
    "        np.logical_not(df['product_name'].isnull()),\n",
    "        np.logical_not(df['countries_en'].isnull())\n",
    "    )]\n",
    "    \n",
    "    # Drop duplicated rows in column product_name\n",
    "    df.drop_duplicates(subset=['product_name'],inplace=True)\n",
    "\n",
    "    print(\"Cleaning process terminated\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading process\n",
    "\n",
    "Now that our loading functions are defined, put some logic here to avoid long time processing while coding.\n",
    "\n",
    "**Do not forget to set the global constant to Production values when coding is finished**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleand CSV file found. Original data file processing is skipped\n"
     ]
    }
   ],
   "source": [
    "if (FORCE_LOAD_ORIGINAL_FILE == True) or path.exists(CLEANED_CSV_FILENAME) == False:\n",
    "    df = loadOriginalTsvFile(ORIGINAL_TSV_FILENAME)\n",
    "    cleanOriginalData(df)\n",
    "    dumpCleanedCsvFile(df, CLEANED_CSV_FILENAME)\n",
    "else:\n",
    "    print(\"Cleand CSV file found. Original data file processing is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the first 10000 rows from  data/OpenFoodFacts-cleaned.csv\n",
      "Please wait...\n",
      "Dataframe loaded\n",
      "Number of rows   : 10000\n",
      "Number of columns: 140\n"
     ]
    }
   ],
   "source": [
    "if MAX_ENTRY_TO_LOAD != None:\n",
    "    print(\"Loading the first\",MAX_ENTRY_TO_LOAD,\"rows from \",CLEANED_CSV_FILENAME)\n",
    "else:\n",
    "    print(\"Loading data from \",CLEANED_CSV_FILENAME)\n",
    "\n",
    "print(\"Please wait...\")\n",
    "df = pd.read_csv(CLEANED_CSV_FILENAME,low_memory=False, nrows=MAX_ENTRY_TO_LOAD, index_col=0)\n",
    "print(\"Dataframe loaded\")\n",
    "\n",
    "print('Number of rows   :',format(df.shape[0]))\n",
    "print('Number of columns:',format(df.shape[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

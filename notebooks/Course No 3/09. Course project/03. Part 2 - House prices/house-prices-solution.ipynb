{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project No 3 - Part 2 - House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all the base libraries that we will use in this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Insight:\n",
    "# Pour les missing values, créer une catégorie missing\n",
    "# Ne pas supprimer les colonnes en première instance, à faire plus tard dans la construction de modèles simples.\n",
    "# Utiliser les histogrammes simples pour évaluer les outliers des colonnes numériques.\n",
    "# Pour les colonnes avec données manquantes, une LinearRegression sera pénalisée alors que les regression type Ridge seront moins sensibles\n",
    "# Le drop de colonne pourra être évalué avec une approche Grid en jouant sur l'alpha du Ridge (si pas d'influence, on ne doit pas trouver d'outfitting\n",
    "# en diminuant la valeur de l'alpha)\n",
    "\n",
    "# !!! Ordinal values: À classer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this second part\n",
    "\n",
    "Estimate the price of 500 houses using a model based on 2'430 house prices, analyzing a dataset made of 82 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "So we have two files, one for the train dataset, the other for the test.\n",
    "\n",
    "As we will have to duplicate, transform, maybe drop columns in both dataset, I've decided to concat both into one big dataset, and define a utility functions that returns test and train values as separated dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset: (2430, 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484</td>\n",
       "      <td>528275070</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8795</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2586</td>\n",
       "      <td>535305120</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10170</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289</td>\n",
       "      <td>923228250</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0    484  528275070           60        RL           NaN      8795   Pave   \n",
       "1   2586  535305120           20        RL          75.0     10170   Pave   \n",
       "2   2289  923228250          160        RM          21.0      2001   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN   NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN   NaN          NaN   \n",
       "2   NaN       Reg          Lvl  ...         0     NaN   NaN          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       4    2009       WD           Normal     236000  \n",
       "1        0       6    2006       WD           Normal     155000  \n",
       "2        0       1    2007       WD           Normal      75000  \n",
       "\n",
       "[3 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join('data','house-prices.csv'))\n",
    "print(\"Size of the train dataset:\", train_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the test dataset: (500, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2217</td>\n",
       "      <td>909279080</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11275</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837</td>\n",
       "      <td>907126050</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9757</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2397</td>\n",
       "      <td>528144030</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>86.0</td>\n",
       "      <td>11065</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0   2217  909279080           50        RL           NaN     11275   Pave   \n",
       "1    837  907126050           20        RL          65.0      9757   Pave   \n",
       "2   2397  528144030           60        RL          86.0     11065   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Screen Porch Pool Area Pool QC Fence  \\\n",
       "0   NaN       IR1          HLS  ...            0         0     NaN   NaN   \n",
       "1   NaN       Reg          Low  ...           92         0     NaN   NaN   \n",
       "2   NaN       IR1          Lvl  ...            0         0     NaN   NaN   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold Yr Sold  Sale Type  Sale Condition  \n",
       "0          NaN        0       3    2007        WD           Normal  \n",
       "1          NaN        0      10    2009        WD           Normal  \n",
       "2          NaN        0      10    2006        New         Partial  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join('data','house-prices-test.csv'))\n",
    "print(\"Size of the test dataset:\", test_df.shape)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets into one dataframe\n",
    "\n",
    "The merged dataset will be stored in a variable named *data_df*\n",
    "\n",
    "> Note: Test dataset is missing the 'SalePrice' column. We must add an empty column to it before concatenating it with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of global dataframe. Must be (2930,82):\t (2930, 82)\n",
      "Size of global dataframe. Must be (2430,82):\t (2430, 82)\n",
      "Size of global dataframe. Must be (500,82):\t (500, 82)\n"
     ]
    }
   ],
   "source": [
    "# Define target column name as a variable\n",
    "target_column='SalePrice'\n",
    "\n",
    "# Add empty 'SalePrice' columnto Test dataset\n",
    "test_df[target_column] = np.nan\n",
    "\n",
    "# Concat both dataframe\n",
    "data_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Verify size of resulting dataframe\n",
    "print(\"Size of global dataframe. Must be (2930,82):\\t\", data_df.shape)\n",
    "\n",
    "# Define function that split back dataframes\n",
    "def getTrainDataset():\n",
    "    global data_df\n",
    "    global target_column\n",
    "    \n",
    "    return data_df[np.logical_not(data_df[target_column].isnull())]\n",
    "\n",
    "# Define function that split back dataframes\n",
    "def getTestDataset():\n",
    "    global data_df\n",
    "    global target_column\n",
    "    \n",
    "    return data_df[data_df[target_column].isnull()]\n",
    "\n",
    "# Verify size of trainig dataframe\n",
    "print(\"Size of global dataframe. Must be (2430,82):\\t\", getTrainDataset().shape)\n",
    "\n",
    "# Verify size of resulting dataframe\n",
    "print(\"Size of global dataframe. Must be (500,82):\\t\", getTestDataset().shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "Before working on our dataset, let's define some utility functions that will be used in our Notebook.\n",
    "This will simplify our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop and One-encode\n",
    "\n",
    "Along the Notebook, we will have to drop columns and one-encode others.\n",
    "\n",
    "Instead of dropping column immediately, we had the columns to drop in a *column_to_drop* set to be removed later. This trick allows us to run cell notebook several time without side effect. Of course, as soon as the drop command is applied on this set, the previous cells might not work and the notebook should be rerun from beginning.\n",
    "\n",
    "Same for one-hot encoding, we define a *columns_to_encode* set() to perform the one-hot encoding later.\n",
    "\n",
    "We create two functions to manipulate those two variables and a third one to execute the job, taking care of the global variables\n",
    "\n",
    "> Note 1: One-hot encoding must be done prior to the drop call as some of the flagged columns to be dropped are created by the 'one-hot' encoding process.\n",
    "\n",
    "> Note 2: Reset the two variables *columns_to_drop* and *columns_to_encode* afterward in case we reuse them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the columns to be dropped\n",
    "columns_to_drop = set()\n",
    "\n",
    "# Store the columns to be ont-hot encoded\n",
    "columns_to_encode = set()\n",
    "\n",
    "# Function to add columns to be dropped\n",
    "def addColumnToDropList(columns = []):\n",
    "    \"\"\"\n",
    "    Adds columns received as parametr to columns_to_drop global var\n",
    "    \"\"\"\n",
    "    global columns_to_drop\n",
    "    for c in columns:\n",
    "        columns_to_drop.add(c)\n",
    "    print(\"Columns flaged as 'to be removed':\", \",\".join(columns_to_drop))\n",
    "\n",
    "# Function to add columns to be one-hot encoded\n",
    "def addColumnToOneHotEncoding(columns = []):\n",
    "    \"\"\"\n",
    "    Adds columns received as parametr to columns_to_encode global var\n",
    "    \"\"\"\n",
    "    global columns_to_encode\n",
    "    for c in columns:\n",
    "        columns_to_encode.add(c)\n",
    "    print(\"Columns flaged as 'to be one-hot encoded':\", \",\".join(columns_to_encode))\n",
    "    \n",
    "def dropAndEncode():\n",
    "    global columns_to_drop\n",
    "    global columns_to_encode\n",
    "    global data_df\n",
    "    \"\"\"\n",
    "    This function handle drop and one-hot encoding on the data_df dataset\n",
    "    \"\"\"\n",
    "    print(\"Size of the dataframe BEFORE applying one-hot encoding:\", data_df.shape)\n",
    "    if (len(columns_to_encode) > 0):\n",
    "        print(\"  Do 'one-hot' encoding on:\", columns_to_encode)\n",
    "        data_df = pd.get_dummies(data_df, columns=columns_to_encode)\n",
    "    print(\"Size of the dataframe AFTER applying one-hot encoding:\", data_df.shape)\n",
    "    if (len(columns_to_drop) > 0):\n",
    "        print(\"  Drop columns:\", columns_to_drop)\n",
    "        data_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    print(\"Size of the dataframe AFTER dropping column and applying one-hot encoding:\", data_df.shape)\n",
    "\n",
    "    # reset global var as the job has been done\n",
    "    columns_to_drop = set()\n",
    "    columns_to_encode = set()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Clause Replacement\n",
    "\n",
    "On columns from which we could extract binary information (for example, does the house has a pool or not?), instead of doing a one-hot encoding exercice after replacing values, we can define a function using the *np.where()* method to globaly modified the column values in one shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whereClauseReplacement(column, condition, suffix=' Exists', true_value=0, false_value=1, drop_original_column = True):\n",
    "    \"\"\"\n",
    "    Function take a np.array of boolean and a column name to apply an np.where call on it.\n",
    "    true_value and false_value default to 1 and 0\n",
    "    The resulting value is added in a new column using the column name parameter and a suffix parameter.\n",
    "    A drop_original_column can be provided to decide if the orignal column should be dropped. It is set by default to True\n",
    "    \"\"\"\n",
    "    \n",
    "    global data_df\n",
    "    \n",
    "    print(\"Doing a binary replacement on column\", column)\n",
    "    new_column = column + suffix\n",
    "    print(\"  New column name:\", new_column)\n",
    "    data_df[new_column] =np.where(condition, true_value, false_value)\n",
    "    if (drop_original_column == True):\n",
    "        print(\"  Drop original column\")\n",
    "        addColumnToDropList([column])\n",
    "    # ensure new column contains at least and no more 2 values\n",
    "    if (len(data_df[new_column].unique()) != 2):\n",
    "        raise SystemExit(\"WARNING: whereClauseReplacement found number of values != 2. Aborting Notebook execution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform literal ordinal column to numerical one\n",
    "\n",
    "Most of the ordinal columns, according to documentation, values in those columns are categories written as strings. The following utility function is used to convert literal values by numeric ones. The mapping between literal and numeric values is passed to the function as a dictionnary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition to rencode ordinal column to numerical \n",
    "def encodeLiteralToNumericValues(column, mapping={}, replacena= None):\n",
    "    \"\"\"\n",
    "    This function replaces values in column passed as parameter using the mapping dict provided.\n",
    "    Key of the dict are used as search value in cells, and if match, cell value is replace by the value\n",
    "    of mapping[key]\n",
    "    replacena parameter, if different from None is used as replacement of null values\n",
    "    Note that dtype of modified column is automatically set to int64 if all values have been replaced with numeric one\n",
    "    Function also prints the unique values found in the column after transformation. This information could be used\n",
    "    to validate that we've not missed any replacement.\n",
    "    We do also ensure that column received as parameter does not contains only a numeric values. if it is the cas, then\n",
    "    the function simply returns.\n",
    "    \"\"\"\n",
    "    global data_df\n",
    "    \n",
    "    print(\"Encoding column {} to numerical values\".format(column))\n",
    "    # Does the column contains only numeric\n",
    "    if pd.api.types.is_numeric_dtype(data_df[column].dtype):\n",
    "        # yes, return\n",
    "        print(\"  Column is already numerical. Nothing to do.\")\n",
    "        return\n",
    "\n",
    "    # replace values using mapping\n",
    "    data_df[column] = data_df[column].map(mapping)\n",
    "    # replace null values\n",
    "    if replacena != None:\n",
    "        data_df[column] = data_df[column].fillna(replacena)\n",
    "\n",
    "        \n",
    "    # Do an exit(1) if resulting column is not a numeric one\n",
    "    if pd.api.types.is_numeric_dtype(data_df[column].dtype) == False:\n",
    "        raise SystemExit(\"WARNING: encodeOrdinalColumnToNumeric returns a non numerical column. Aborting Notebook execution\")\n",
    "    else:\n",
    "        print(\"  Column successfully encoded with numerical values\")\n",
    "    print(\"  Values in column:\", data_df[column].unique())\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "Data in this set is not optimal and has to be cleaned before being used. Here is the methodology followed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop useless columns\n",
    "\n",
    "Order and PID columns are useless to fit models. Drop it :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be removed': Order,PID\n"
     ]
    }
   ],
   "source": [
    "addColumnToDropList(['Order','PID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle columns with more than 20% empty cells\n",
    "Some of the columns contains a huge amount of null cells, we should drop them as they won't be pertinent if we were seeking for data quality.\n",
    "But, in Machine Learning approach, it's a better choice to keep all the data available, modifying it a little bit to suit model fitting process.\n",
    "Why seeking for 20% of empty cells in columns ? No specific reason, arbitrary choice :-)\n",
    "\n",
    "Let's identify those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with mode than 20% of empty cells: Alley,Fireplace Qu,Pool QC,Fence,Misc Feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pool QC         2917\n",
       "Misc Feature    2824\n",
       "Alley           2732\n",
       "Fence           2358\n",
       "Fireplace Qu    1422\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of lines in dataset\n",
    "total_line = data_df.shape[0]\n",
    "\n",
    "# NULL_CELL_LIMIT is the max allowed percentage of null value in a column\n",
    "NULL_CELL_LIMIT = 0.20\n",
    "\n",
    "# List of columns that we will drop\n",
    "identified_column = list()\n",
    "\n",
    "# Loop in each column and identify the one to drop\n",
    "for c in data_df.columns:\n",
    "    no_of_null_cell = data_df[c].isnull().sum()\n",
    "    if(no_of_null_cell/total_line > NULL_CELL_LIMIT):\n",
    "        identified_column.append(c)\n",
    "\n",
    "print(\"Columns with mode than 20% of empty cells:\", ','.join(identified_column))\n",
    "\n",
    "data_df[identified_column].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've found 5 columns. Here is what I've decided to do with them.\n",
    "\n",
    "#### Pool QC: \n",
    "\n",
    "On the whole dataset, we found that only 12 houses are equiped with a pool.\n",
    "Choice is made to do a one-hot encoding on the 'Pool QC' column to simply identify houses with a pool, by replacing null values by 0, others by 1.\n",
    "\n",
    "To simplify coding, we define here a function that performs the 'where' binary replacement on a list of dataset, which defaults to our previously initialized variable: dataframe_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of houses with pool:\t 13\n",
      "Number of pool area > 0:\t 13\n",
      "Doing a binary replacement on column Pool QC\n",
      "  New column name: Pool QC Exists\n",
      "  Drop original column\n",
      "Columns flaged as 'to be removed': Order,PID,Pool QC\n"
     ]
    }
   ],
   "source": [
    "# Ensure that number of houses without a pool is in line with the poll size information (only houses with\n",
    "# a pool should have a pool area above 0)\n",
    "print(\"Number of houses with pool:\\t\",data_df.shape[0] - data_df['Pool QC'].isnull().sum())\n",
    "print(\"Number of pool area > 0:\\t\",data_df[data_df['Pool Area'] > 0]['Pool Area'].count())\n",
    "\n",
    "whereClauseReplacement('Pool QC', data_df['Pool QC'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alley\n",
    "NaN means house without alley. We should split the 'Alley' information into two different one: Does the house has an alley, and what type is the alley.\n",
    "Do a hot encoding on alley to get the 'Alley Type' for each house, and another one-hot encoding on 'Alley' to get the 'Alley Exists' column. For the alley_exists one hot encoding, we use our previous defined function binaryNullWhereClauseReplacement()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be one-hot encoded': Alley Type\n",
      "Doing a binary replacement on column Alley\n",
      "  New column name: Alley Exists\n",
      "  Drop original column\n",
      "Columns flaged as 'to be removed': Alley,Order,PID,Pool QC\n"
     ]
    }
   ],
   "source": [
    "# Duplicate 'Alley' column to 'Alley Type' in all dataframe\n",
    "data_df['Alley Type'] = data_df['Alley']\n",
    "\n",
    "# Do a one hot encoding on 'Allay Type'\n",
    "addColumnToOneHotEncoding(['Alley Type'])\n",
    "\n",
    "# Create 'Alley Exists'\n",
    "whereClauseReplacement('Alley', data_df['Alley'].isnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc Feature\n",
    "\n",
    "Misc Feature store informations on features that do not match any other columns. Approach here is to perform a simple 'one-hot' encoding which will remove the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be one-hot encoded': Alley Type,Misc Feature\n"
     ]
    }
   ],
   "source": [
    "addColumnToOneHotEncoding(['Misc Feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fence\n",
    "\n",
    "Fence information should be used to reflect only if the house has a fence or not. Other informations are not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details on the 'Fence' column content:\n",
      "       PID\n",
      "Fence     \n",
      "MnPrv  330\n",
      "GdPrv  118\n",
      "GdWo   112\n",
      "MnWw    12\n",
      "Doing a binary replacement on column Fence\n",
      "  New column name: Fence Exists\n",
      "  Drop original column\n",
      "Columns flaged as 'to be removed': Fence,Pool QC,PID,Order,Alley\n"
     ]
    }
   ],
   "source": [
    "print(\"Details on the 'Fence' column content:\")\n",
    "print(data_df[['Fence','PID']].groupby('Fence').count().sort_values('PID', ascending=False))\n",
    "\n",
    "# Create 'Fence Exists'\n",
    "whereClauseReplacement('Fence', data_df['Fence'].isnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fireplace Qu\n",
    "\n",
    "We use the same approach as Pools for Fireplaces.\n",
    "\n",
    "First check that number of houses with a Fireplace Quality not null is equal to the number of houses with a number of Fireplace above 0.\n",
    "\n",
    "As it is the case, then create a 'Fireplace Exist' to distinguish houses with at least one fireplace.\n",
    "\n",
    "Regarding the Fireplace Quality column, documentation says that it's an ordinal column. Instead of doing a one-hot encoding, let's replace values in that column with numeric values representing the ordinal classification of firaplace quality.\n",
    "\n",
    "> Note: We define a function to modify ordinal string encoding by numeric values, as we will repeat this operation later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of houses with fireplace quality evaluation:\t 1508\n",
      "Number of houses with at least one fireplace:\t\t 1508\n",
      "Convert Ordinal column to numerical\n",
      "Encoding column Fireplace Quality to numerical values\n",
      "  Column successfully encoded with numerical values\n",
      "  Values in column: [3. 4. 0. 2. 1. 5.]\n",
      "Doing a binary replacement on column Fireplace\n",
      "  New column name: Fireplace Exists\n",
      "  Drop original column\n",
      "Columns flaged as 'to be removed': Fence,Fireplace,Pool QC,PID,Order,Alley\n",
      "Columns flaged as 'to be removed': Fence,Fireplace,Fireplace Qu,Pool QC,PID,Order,Alley\n"
     ]
    }
   ],
   "source": [
    "# Ensure that number of houses without a pool is in line with the poll size information (only houses with\n",
    "# a pool should have a pool area above 0)\n",
    "print(\"Number of houses with fireplace quality evaluation:\\t\",data_df.shape[0] - data_df['Fireplace Qu'].isnull().sum())\n",
    "print(\"Number of houses with at least one fireplace:\\t\\t\",data_df[data_df['Fireplaces'] > 0]['Fireplaces'].count())\n",
    "\n",
    "# Make a copies of Fireplace Qu\n",
    "data_df['Fireplace'] = data_df['Fireplace Qu'] # Warning, a Fireplaces column exists, beware of the 's'\n",
    "data_df['Fireplace Quality'] = data_df['Fireplace Qu']\n",
    "\n",
    "# Re-encode column\n",
    "print(\"Convert Ordinal column to numerical\")\n",
    "fireplace_mapping = { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 }\n",
    "encodeLiteralToNumericValues(column='Fireplace Quality', mapping=fireplace_mapping, replacena=0)\n",
    "\n",
    "# Replace null values in 'Pool QC' by 0, non null by 1, keep original column\n",
    "whereClauseReplacement('Fireplace', data_df['Fireplace'].isnull())\n",
    "\n",
    "# Do not forget to drop 'Fireplace Qu' as it is not usefull anymore\n",
    "addColumnToDropList(['Fireplace Qu'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode and drop columns identified previously\n",
    "\n",
    "It's now time to 'one-hot' encode and drop identified columns above using our function dropAndEncode() defined above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop and one-hot encode\n",
      "Size of the dataframe BEFORE applying one-hot encoding: (2930, 89)\n",
      "  Do 'one-hot' encoding on: {'Alley Type', 'Misc Feature'}\n",
      "Size of the dataframe AFTER applying one-hot encoding: (2930, 94)\n",
      "  Drop columns: {'Fence', 'Fireplace', 'Fireplace Qu', 'Pool QC', 'PID', 'Order', 'Alley'}\n",
      "Size of the dataframe AFTER dropping column and applying one-hot encoding: (2930, 87)\n"
     ]
    }
   ],
   "source": [
    "print(\"Drop and one-hot encode\")\n",
    "dropAndEncode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove lines with empty cells on columns with a few empty values\n",
    "\n",
    "Some of the remaining column after this first cleaning still contains empty cells. Decision is made to drop all the lines that contains null values in the columns where the total number of null values in those columns is not null and lower than a fixed value.\n",
    "\n",
    "To evaluate the fixed value, we will try different one and maesure how much line will be dropped. If the result is less the 20%, then it's a good choice. 20% of the test dataframe represents around 80% of the test dataset, which is an acceptable factor.\n",
    "\n",
    "> Note: This has to be done on the Train dataset only as we dont wan't to drop lines of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting size of the Dataframe (factor =   0) = 2430/2430 (ratio = 100.00%)\n",
      "Resulting size of the Dataframe (factor =  10) = 2426/2430 (ratio = 99.84%)\n",
      "Resulting size of the Dataframe (factor = 100) = 2333/2430 (ratio = 96.01%)\n",
      "Resulting size of the Dataframe (factor = 200) = 2209/2430 (ratio = 90.91%)\n",
      "Resulting size of the Dataframe (factor = 300) = 2209/2430 (ratio = 90.91%)\n",
      "Resulting size of the Dataframe (factor = 400) = 2209/2430 (ratio = 90.91%)\n",
      "Resulting size of the Dataframe (factor = 500) = 1815/2430 (ratio = 74.69%)\n"
     ]
    }
   ],
   "source": [
    "temp_df = getTrainDataset().copy()\n",
    "\n",
    "# Sum number of empty cells per column\n",
    "null_sum_df = temp_df.isnull().sum().to_frame()\n",
    "\n",
    "# A dictionnary that will contain the different dataframe\n",
    "train_df_list = dict()\n",
    "\n",
    "for i in (0, 10, 100, 200, 300, 400, 500):\n",
    "    columns_df = null_sum_df[np.logical_and(null_sum_df[0] > 0, null_sum_df[0] < i)]\n",
    "    bool_filter = temp_df[columns_df.index.values.tolist()].isnull().values.any(axis=1)\n",
    "    train_df_list[i] = temp_df[np.logical_not(bool_filter)]\n",
    "    df_size = train_df_list[i].shape[0]\n",
    "    print(\"Resulting size of the Dataframe (factor = {:3}) = {}/{} (ratio = {:.2f}%)\".format(i,df_size,temp_df.shape[0],(df_size/temp_df.shape[0])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our previous test, if we drop all the lines where, in the corresponding columns, the number of empty cells are not null and below 400, we do remove around 200 lines, which is acceptable. Our dataframe should now take the value data_df_list[400].\n",
    "\n",
    "And finally, we remain with only one column containing null values: Lot Frontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 90)\n",
      "(2209, 87)\n",
      "(2430, 90)\n",
      "(500, 90)\n"
     ]
    }
   ],
   "source": [
    "temp_df = train_df_list[400]\n",
    "# Display columns with empty values, sorted descending\n",
    "# Ignore SalePrice as it is normal that we have null values in it (it's our test set)\n",
    "train_df_list[400].drop('SalePrice',axis=1).isnull().sum().to_frame().sort_values(0, ascending = False).head(10)\n",
    "print(data_df.shape)\n",
    "print(temp_df.shape)\n",
    "print(getTrainDataset().shape)\n",
    "print(getTestDataset().shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at this column to determine what to do with empty cells.\n",
    "\n",
    "Best option at that time, draw an histogram graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['Lot Frontage'].plot.hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous graph shows that we have some outliers in this columns, and most of the datapoints are centered on a value around 60.\n",
    "\n",
    "The approach we can choose to handle null values in this column is to replace them by the mean value of the column, without the outliers and null values. See below the new histogram and the mean value calculated. This value will be used to replace null values in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value calculated with the reduced dataset: 68.46\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['Lot Frontage'][np.logical_and(data_df['Lot Frontage'] < 150, data_df['Lot Frontage'] > 0)].plot.hist(bins=20)\n",
    "mean_value = data_df['Lot Frontage'][np.logical_and(data_df['Lot Frontage'] < 150, data_df['Lot Frontage'] > 0)].mean()\n",
    "print(\"Mean value calculated with the reduced dataset: {:.2f}\".format(mean_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in dataframe: 1754\n",
      "Dataframe size: (2930, 87)\n",
      "Good :-)\n"
     ]
    }
   ],
   "source": [
    "data_df['Lot Frontage'] = data_df['Lot Frontage'].fillna(int(mean_value))\n",
    "\n",
    "print(\"Number of null value in dataframe:\", data_df.isnull().sum().sum())\n",
    "print(\"Dataframe size:\", data_df.shape)\n",
    "print(\"Good :-)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine. Our dataset has now 0 null values. It's time now to perform feature encoding and feature engineering \n",
    "\n",
    "Before that, let's classify columns in four categories using the documentation provided with the dataset. Goal is to build 4 list of column names, one for each type: continuous, nominal, ordinal and discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of column not classified: 14\n",
      "Column names: Alley Exists,Alley Type_Grvl,Alley Type_Pave,Fence Exists,Fireplace Exists,Fireplace Quality,Lot Frontage,Misc Feature_Elev,Misc Feature_Gar2,Misc Feature_Othr,Misc Feature_Shed,Misc Feature_TenC,Pool QC Exists,Utilities\n"
     ]
    }
   ],
   "source": [
    "# Continuous variables\n",
    "continuous_column = [\n",
    "    '1st Flr SF', '2nd Flr SF', 'Lot Frontage Clean', 'Lot Area', 'Mas Vnr Area', 'Bsmt Unf SF', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Total Bsmt SF',\n",
    "    'Low Qual Fin SF', 'Gr Liv Area', 'Garage Area', '3Ssn Porch', 'Open Porch SF', 'Wood Deck SF', 'Pool Area', 'Screen Porch', 'Misc Val', 'Enclosed Porch',\n",
    "]\n",
    "\n",
    "# Nominal variables - no possible ordering\n",
    "nominal_column = [\n",
    "    'MS SubClass', 'MS Zoning', 'Street', 'Land Contour', 'Lot Config', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Exterior 1st',\n",
    "    'Exterior 2nd', 'Roof Matl', 'Roof Style', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', 'Sale Condition', 'Sale Type', 'Street',\n",
    "]\n",
    "\n",
    "# Ordinal variables - you can order the categories\n",
    "ordinal_column =[\n",
    "    'Lot Shape', 'Land Slope', 'Overall Cond', 'Overall Qual', 'Exter Cond', 'Exter Qual', 'Bsmt Cond', 'Bsmt Qual', 'Bsmt Exposure', 'BsmtFin Type 1',\n",
    "    'BsmtFin Type 2', 'Heating QC', 'Electrical', 'Kitchen Qual', 'Functional', 'Garage Finish', 'Garage Cond', 'Garage Qual', 'Paved Drive',\n",
    "]\n",
    "\n",
    "# Discrete variables - categories are integer values\n",
    "discrete_column = [\n",
    "    'Year Built', 'Year Remod/Add', 'Mo Sold', 'Yr Sold', 'Full Bath', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Half Bath', 'TotRms AbvGrd', 'Fireplaces',\n",
    "    'Garage Yr Blt', 'Garage Cars', 'Bedroom AbvGr', 'Kitchen AbvGr',\n",
    "]\n",
    "\n",
    "y_column = [\n",
    " 'SalePrice',\n",
    "]\n",
    "\n",
    "# This trick should return an the columns we've one-hot encoded above, number of these should be 15\n",
    "unclassified_columns = set(data_df.columns.values.tolist()) - set(continuous_column) - set(nominal_column) - set(ordinal_column) - set(discrete_column) - set(y_column)\n",
    "print(\"Number of column not classified:\",len(unclassified_columns))\n",
    "print(\"Column names:\",','.join(sorted(unclassified_columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal columns\n",
    "\n",
    "Let's consider first the ordinal columns, and convert them to numerical column for better model fitting, using our previous encodeOrdinalColumnToNumeric() function.\n",
    "\n",
    "Looking at some of those columns, we must perform some more data cleaning before converting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basement\n",
    "\n",
    "Basement information are contained in 8 Bsmt* columns plus 'Total Bsmt SF'. 5 of them are ordinal:\n",
    "* Bsmt Cond\n",
    "* Bsmt Exposure\n",
    "* Bsmt Qual\n",
    "* BsmtFin Type 1\n",
    "* BsmtFin Type 2\n",
    "\n",
    "We will encode them as numerical column, which will remove null values, and build another column which states if the house has a basement. This new column will be based on the 'Total Bsml SF' column and will be 'one-hot' encoded.\n",
    "\n",
    "Before that, I do a small control to ensure that Total Bsmt SF = Bsmt 1 SF + Bsmt 2 SF + Basmt Unfinished SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     2929\n",
      "False       1\n",
      "Name: Equal ?, dtype: int64\n",
      "No False result, equality between cells about Square Feet is respected\n"
     ]
    }
   ],
   "source": [
    "temp_df = data_df[['Total Bsmt SF','Bsmt Unf SF','Bsmt Cond','Bsmt Exposure','Bsmt Qual','BsmtFin Type 1','BsmtFin Type 2','BsmtFin SF 1','BsmtFin SF 2']].copy()\n",
    "temp_df['Sum'] = data_df['BsmtFin SF 1'] + data_df['BsmtFin SF 2'] + data_df['Bsmt Unf SF']\n",
    "temp_df['Equal ?'] = temp_df['Sum'] == temp_df['Total Bsmt SF']\n",
    "print(temp_df['Equal ?'].value_counts())\n",
    "print(\"No False result, equality between cells about Square Feet is respected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing is the ordinal value 'Unf' in 'BsmtFin Type 1' and 'BsmFin Type 2'. This value does not evaluate the quality of the basement but the fact that it is not finished.\n",
    "\n",
    "I will then create two new columns 'Bsmt Type 1 Exists' and 'Bsmt Type 2 Exists' with 1 or 0 value. Then, on the BsmtFin Type 1 & 2 column, I will replace 'Unf' values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encodeOrdinalColumnToNumeric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ff550b02b366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mencodeOrdinalColumnToNumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacena\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encodeOrdinalColumnToNumeric' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Basement Exists, Bsmt Type 1 & 2 Unf and one encode them\n",
    "data_df['Bsmt Exists'] = np.where(data_df['Total Bsmt SF'] == 0, 0, 1)\n",
    "data_df['Bsmt Type 1 Exists'] = np.where(data_df['BsmtFin Type 1'] == 'Unf', 0, 1)\n",
    "data_df['Bsmt Type 2 Exists'] = np.where(data_df['BsmtFin Type 2'] == 'Unf', 0, 1)\n",
    "ordinal_column.extend(['Bsmt Exists', 'Bsmt Type 1 Exists','Bsmt Type 2 Exists'])\n",
    "# DO NOT FORGET TO REPLICATE THAT CHANGE IN test_df\n",
    "test_df['Bsmt Exists'] = np.where(test_df['Total Bsmt SF'] == 0, 0, 1)\n",
    "test_df['Bsmt Type 1 Exists'] = np.where(test_df['BsmtFin Type 1'] == 'Unf', 0, 1)\n",
    "test_df['Bsmt Type 2 Exists'] = np.where(test_df['BsmtFin Type 2'] == 'Unf', 0, 1)\n",
    "\n",
    "\n",
    "# Convert ordinal Bsmt columns to numerical\n",
    "mapping = {\n",
    "    'Bsmt Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Bsmt Cond': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Bsmt Exposure': { 'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1 },\n",
    "    'BsmtFin Type 1': { 'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0 },\n",
    "    'BsmtFin Type 2': { 'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0 },\n",
    "}\n",
    "for c in mapping:\n",
    "    encodeOrdinalColumnToNumeric(data_df, column=c, mapping=mapping[c], replacena=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities\n",
    "\n",
    "The 'Utilities' ordinal column is a bit special as all but three entries are identical. This let me think that this information is really not usefull to fit a model.\n",
    "\n",
    "Instead of dropping this columns, I would prefer to drop the three lines that are different from the rest. This will avoid having outliers in our train dataset for house sale prices as these three houses do not have all the basic utilities. Furthermode, a look at the test dataset shows that we do have only houses in this 500 lines dataset with all the Utilities. Loosing information on how much incomplete utilities can modify the sale price is useless here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Existing values in 'Utilities' column of the test dataset is unique:\")\n",
    "print(test_df['Utilities'].value_counts())\n",
    "print(\"We can drop the 'Utilities' and column from the train dataset and remove the three houses\")\n",
    "\n",
    "# Remove the three houses that do not have all the utilities\n",
    "data_df = data_df[data_df['Utilities'] == 'AllPub']\n",
    "addColumnToDropList(['Utilities'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garage\n",
    "\n",
    "Garage is nearly the same as for Basement. Some of the houses do not have garage.\n",
    "\n",
    "Best way shoulod be to create a new column 'Has Garage' and convert ordinal Garage columns to numerical values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Garage Exists and one encode it (do not forget test_df)\n",
    "data_df['Garage Exists'] = np.where(data_df['Garage Area'] == 0, 0, 1)\n",
    "test_df['Garage Exists'] = np.where(test_df['Garage Area'] == 0, 0, 1)\n",
    "# addColumnToOneHotEncoding(['Has Garage'])\n",
    "\n",
    "# Convert ordinal Garage columns to numerical\n",
    "mapping = {\n",
    "    'Garage Finish': {'Fin': 3, 'RFn': 2, 'Unf': 1 },\n",
    "    'Garage Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Garage Cond': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "}\n",
    "\n",
    "for c in mapping:\n",
    "    encodeOrdinalColumnToNumeric(data_df, column=c, mapping=mapping[c], replacena=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining ordinal columns\n",
    "\n",
    "The remaining ordinal columns are simply re-encoded using numerical values, except for 'Overall Cond' and 'Overall Qual' as those two columns are already ordinal ones with numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Electrical': { 'SBrkr': 5, 'FuseA': 4,'FuseF': 3,'FuseP': 2, 'Mix': 1 },\n",
    "    'Exter Cond': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Exter Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Functional': { 'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 0 },\n",
    "    'Heating QC': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Kitchen Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Land Slope': { 'Gtl': 3, 'Mod': 2, 'Sev': 1 },\n",
    "    'Lot Shape': { 'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1 },\n",
    "    'Paved Drive': { 'Y': 3, 'P': 2, 'N': 1 },\n",
    "}\n",
    "\n",
    "for c in mapping:\n",
    "    encodeOrdinalColumnToNumeric(data_df, column=c, mapping=mapping[c], replacena=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up\n",
    "\n",
    "Now that all our ordinal column have been transformed and/or re-encoded, let's drop and one-hot encode the columns and check that our ordinal columns of our dataframe are all dtype = numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropAndEncode()\n",
    "\n",
    "data_df[ordinal_column].dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominal columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding nominal columns, option is very simple. We must perform one-hot encoding on each to get numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addColumnToOneHotEncoding(nominal_column)\n",
    "dropAndEncode()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete columns\n",
    "\n",
    "* Find the houses solded as new one\n",
    "* Find houses that have been remoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in sorted(discrete_column):\n",
    "    print(c,\":\\t\",sorted(data_df[c].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data_df.select_dtypes(np.number):\n",
    "    c_mean = data_df[c].mean()\n",
    "    c_std  = data_df[c].std()\n",
    "    z_min  = (c_mean-data_df[c].min())/c_std\n",
    "    z_max  = (data_df[c].max()-c_mean)/c_std\n",
    "    outliers = ''\n",
    "    if (z_min > 2 or z_max > 2):\n",
    "        outliers = '(outliers)'\n",
    "    #print(\"Column {:20s} mean:{:9.2f}\\tstd:{:9.2f}\\tz-min:{:9.2f}\\tz-max:{:10.2f} {}\".format(c, c_mean, c_std, z_min, z_max, outliers))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Pool Area'].sort_values(ascending=False)\n",
    "temp_df = data_df[data_df['Pool Area'] > 0]\n",
    "plt.scatter(temp_df['Pool Area'], temp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data_df[continuous_column].hist(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communicating the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

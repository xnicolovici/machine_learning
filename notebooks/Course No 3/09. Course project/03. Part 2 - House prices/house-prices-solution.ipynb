{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project No 3 - Part 2 - House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all the base libraries that we will use in this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Insight:\n",
    "# Pour les missing values, créer une catégorie missing\n",
    "# Ne pas supprimer les colonnes en première instance, à faire plus tard dans la construction de modèles simples.\n",
    "# Utiliser les histogrammes simples pour évaluer les outliers des colonnes numériques.\n",
    "# Pour les colonnes avec données manquantes, une LinearRegression sera pénalisée alors que les regression type Ridge seront moins sensibles\n",
    "# Le drop de colonne pourra être évalué avec une approche Grid en jouant sur l'alpha du Ridge (si pas d'influence, on ne doit pas trouver d'outfitting\n",
    "# en diminuant la valeur de l'alpha)\n",
    "\n",
    "# !!! Ordinal values: À classer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this second part\n",
    "\n",
    "Estimate the price of 500 houses using a model based on 2'430 house prices, analyzing a dataset made of 82 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "I use here the Dataframe.name property to store a name for each dataframe loaded. This information will be used next in this Notebook to identify the dataframe we are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2217</td>\n",
       "      <td>909279080</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11275</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837</td>\n",
       "      <td>907126050</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9757</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2397</td>\n",
       "      <td>528144030</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>86.0</td>\n",
       "      <td>11065</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0   2217  909279080           50        RL           NaN     11275   Pave   \n",
       "1    837  907126050           20        RL          65.0      9757   Pave   \n",
       "2   2397  528144030           60        RL          86.0     11065   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Screen Porch Pool Area Pool QC Fence  \\\n",
       "0   NaN       IR1          HLS  ...            0         0     NaN   NaN   \n",
       "1   NaN       Reg          Low  ...           92         0     NaN   NaN   \n",
       "2   NaN       IR1          Lvl  ...            0         0     NaN   NaN   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold Yr Sold  Sale Type  Sale Condition  \n",
       "0          NaN        0       3    2007        WD           Normal  \n",
       "1          NaN        0      10    2009        WD           Normal  \n",
       "2          NaN        0      10    2006        New         Partial  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join('data','house-prices-test.csv'))\n",
    "test_df.name = 'Test Dataset'\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484</td>\n",
       "      <td>528275070</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8795</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2586</td>\n",
       "      <td>535305120</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10170</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289</td>\n",
       "      <td>923228250</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0    484  528275070           60        RL           NaN      8795   Pave   \n",
       "1   2586  535305120           20        RL          75.0     10170   Pave   \n",
       "2   2289  923228250          160        RM          21.0      2001   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN   NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN   NaN          NaN   \n",
       "2   NaN       Reg          Lvl  ...         0     NaN   NaN          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       4    2009       WD           Normal     236000  \n",
       "1        0       6    2006       WD           Normal     155000  \n",
       "2        0       1    2007       WD           Normal      75000  \n",
       "\n",
       "[3 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(os.path.join('data','house-prices.csv'))\n",
    "data_df.name = 'Train Dataset'\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "Data in this set is not optimal and has to be cleaned before being used. Here is the methodology followed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop useless columns\n",
    "\n",
    "Order and PID columns are useless to fit models. Drop it :-)\n",
    "\n",
    "> Note 1: Instead of dropping column right now, we had the columns to drop in a 'column_to_drop' set to removed them later. This trick allows us to run many cell notebook several time without side effect. Of course, as soon as the drop command is applied on this set, the previous cells might not work and the notebook should be rerun from beginning.\n",
    "\n",
    "> Note 2: Same for one-hot encoding, we define a 'columns_to_encode' set to perform the one-hot encoding later.\n",
    "\n",
    "> Note 3: We create two functions to manipulate those two variables and a third one to execute the job, taking care of the global variables\n",
    "\n",
    "> Note 4: One-hot encoding must be done prior to the drop call as some of the flagged columns to be dropped are created by the 'one-hot' encoding process.\n",
    "\n",
    "> Note 5: Reset the tow variables columns_to_drop and columns_to_encode afterward as we will use them again in the rest of that Notebook\n",
    "\n",
    "Those utilities function takes a dataframe_list as parameter which defaults to a list containing our Train and Test dataset. Changes on dataset must be done at the same time on both dataset, using those convinient fuinctions simpify the Notebook code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the columns to be dropped\n",
    "columns_to_drop = set()\n",
    "\n",
    "# Store the columns to be ont-hot encoded\n",
    "columns_to_encode = set()\n",
    "\n",
    "# List of dataframe to manipulate\n",
    "dataframe_list = [data_df, test_df]\n",
    "\n",
    "# Function to add columns to be dropped\n",
    "def addColumnToDropList(columns = []):\n",
    "    for c in columns:\n",
    "        columns_to_drop.add(c)\n",
    "    print(\"Columns flaged as 'to be removed':\", \",\".join(columns_to_drop))\n",
    "\n",
    "# Function to add columns to be one-hot encoded\n",
    "def addColumnToOneHotEncoding(columns = []):\n",
    "    for c in columns:\n",
    "        columns_to_encode.add(c)\n",
    "    print(\"Columns flaged as 'to be one-hot encoded':\", \",\".join(columns_to_encode))\n",
    "    \n",
    "def dropAndEncode(df_list = dataframe_list, columns_to_encode = columns_to_encode, columns_to_drop = columns_to_drop):\n",
    "    GLOBAL VAR\n",
    "    \"\"\"\n",
    "    This function handle drop and one-hot encoding on the datasets provided as parameter 1\n",
    "    \"\"\"\n",
    "    \n",
    "    for df in df_list:\n",
    "        print(\"Working on dataframe:\", df.name)\n",
    "        if (len(columns_to_encode) > 0):\n",
    "            print(\"  Do 'one-hot' encoding on:\", columns_to_encode)\n",
    "            df= pd.get_dummies(df, columns=columns_to_encode)\n",
    "        if (len(columns_to_drop) > 0):\n",
    "            print(\"  Drop columns:\", columns_to_drop)\n",
    "            df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # reset global var as the job has been done\n",
    "    columns_to_drop = set()\n",
    "    columns_to_encode = set()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be removed': Order,PID\n"
     ]
    }
   ],
   "source": [
    "addColumnToDropList(['Order','PID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle columns with more than 20% empty cells\n",
    "Some of the columns contains a huge amount of null cells, we should drop them as they won't be pertinent if we were seeking for data quality.\n",
    "But, in Machine Learning approach, it's a better choice to keep all the data available, modifying it a little bit to suit model fitting process.\n",
    "Why seeking for 20% of empty cells in columns ? No specific reason, arbitrary choice :-)\n",
    "\n",
    "Let's identify those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with mode than 20% of empty cells: Alley,Fireplace Qu,Pool QC,Fence,Misc Feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pool QC         2418\n",
       "Misc Feature    2340\n",
       "Alley           2267\n",
       "Fence           1941\n",
       "Fireplace Qu    1186\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of lines in dataset\n",
    "total_line = data_df.shape[0]\n",
    "\n",
    "# NULL_CELL_LIMIT is the max allowed percentage of null value in a column\n",
    "NULL_CELL_LIMIT = 0.20\n",
    "\n",
    "# List of columns that we will drop\n",
    "identified_column = list()\n",
    "\n",
    "# Loop in each column and identify the one to drop\n",
    "for c in data_df.columns:\n",
    "    no_of_null_cell = data_df[c].isnull().sum()\n",
    "    if(no_of_null_cell/total_line > NULL_CELL_LIMIT):\n",
    "        identified_column.append(c)\n",
    "\n",
    "print(\"Columns with mode than 20% of empty cells:\", ','.join(identified_column))\n",
    "\n",
    "data_df[identified_column].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've found 5 columns. Here is what I've decided to do with them.\n",
    "\n",
    "#### Pool QC: \n",
    "\n",
    "On the whole dataset, we found that only 12 houses are equiped with a pool.\n",
    "Choice is made to do a one-hot encoding on the 'Pool QC' column to simply identify houses with a pool, by replacing null values by 0, others by 1.\n",
    "\n",
    "To simplify coding, we define here a function that performs the 'where' binary replacement on a list of dataset, which defaults to our previously initialized variable: dataframe_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of houses with pool:\t 12\n",
      "Number of pool area > 0:\t 12\n",
      "Doing a binary replacement on Train Dataset [Pool QC]\n",
      "New column name: Pool QC Exists\n",
      "Drop original column\n",
      "Columns flaged as 'to be removed': Order,Pool QC,PID\n",
      "Doing a binary replacement on Test Dataset [Pool QC]\n",
      "New column name: Pool QC Exists\n",
      "Drop original column\n",
      "Columns flaged as 'to be removed': Order,Pool QC,PID\n"
     ]
    }
   ],
   "source": [
    "# Ensure that number of houses without a pool is in line with the poll size information (only houses with\n",
    "# a pool should have a pool area above 0)\n",
    "print(\"Number of houses with pool:\\t\",data_df.shape[0] - data_df['Pool QC'].isnull().sum())\n",
    "print(\"Number of pool area > 0:\\t\",data_df[data_df['Pool Area'] > 0]['Pool Area'].count())\n",
    "\n",
    "def binaryNullWhereClauseReplacement(column, suffix=' Exists', dataframe_list=dataframe_list, true_value=0, false_value=1, drop_original_column = True):\n",
    "    for df in dataframe_list:\n",
    "        print(\"Doing a binary replacement on\",df.name,\"[{}]\".format(column))\n",
    "        new_column = column + suffix\n",
    "        print(\"New column name:\", new_column)\n",
    "        df[new_column] =np.where(df[column].isnull(), true_value, false_value)\n",
    "        if (drop_original_column == True):\n",
    "            print(\"Drop original column\")\n",
    "            addColumnToDropList([column])\n",
    "        # ensure new column contains at least and no more 2 values\n",
    "        if (len(df[new_column].unique()) != 2):\n",
    "            raise SystemExit(\"WARNING: binaryNullWhereClauseReplacement found number of values != 2. Aborting Notebook execution\")\n",
    "\n",
    "binaryNullWhereClauseReplacement('Pool QC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alley\n",
    "NaN means house without alley. We should split the 'Alley' information into two different one: Does the house has an alley, and what type is the alley.\n",
    "Do a hot encoding on alley to get the 'Alley Type' for each house, and another one-hot encoding on 'Alley' to get the 'Alley Exists' column. For the alley_exists one hot encoding, we use our previous defined function binaryNullWhereClauseReplacement()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be one-hot encoded': Alley Type,Misc Feature\n",
      "Doing a binary replacement on Train Dataset [Alley]\n",
      "New column name: Alley Exists\n",
      "Drop original column\n",
      "Columns flaged as 'to be removed': Pool QC,Fence,PID,Alley,Order\n",
      "Doing a binary replacement on Test Dataset [Alley]\n",
      "New column name: Alley Exists\n",
      "Drop original column\n",
      "Columns flaged as 'to be removed': Pool QC,Fence,PID,Alley,Order\n"
     ]
    }
   ],
   "source": [
    "# Duplicate 'Alley' column to 'Alley Type' in all dataframe\n",
    "for df in dataframe_list:\n",
    "    df['Alley Type'] = df['Alley']\n",
    "\n",
    "# Do a one hot encoding on 'Allay Type'\n",
    "addColumnToOneHotEncoding(['Alley Type'])\n",
    "\n",
    "# Create 'Alley Exists'\n",
    "binaryNullWhereClauseReplacement('Alley')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc Feature\n",
    "\n",
    "Misc Feature store informations on features that do not match any other columns. Approach here is to perform a simple 'one-hot' encoding which will remove the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be one-hot encoded': Alley Type,Misc Feature\n"
     ]
    }
   ],
   "source": [
    "addColumnToOneHotEncoding(['Misc Feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fence\n",
    "\n",
    "Fence information should be used to reflect only if the house has a fence or not. Other informations are not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details on the 'Fence' column content:\n",
      "       PID\n",
      "Fence     \n",
      "MnPrv  288\n",
      "GdPrv   97\n",
      "GdWo    94\n",
      "MnWw    10\n",
      "Doing a binary replacement on Train Dataset [Fence]\n",
      "New column name: Fence Exists\n",
      "Drop original column\n",
      "Columns flaged as 'to be removed': Pool QC,Fence,PID,Alley,Order\n",
      "Doing a binary replacement on Test Dataset [Fence]\n",
      "New column name: Fence Exists\n",
      "Drop original column\n",
      "Columns flaged as 'to be removed': Pool QC,Fence,PID,Alley,Order\n"
     ]
    }
   ],
   "source": [
    "print(\"Details on the 'Fence' column content:\")\n",
    "print(data_df[['Fence','PID']].groupby('Fence').count().sort_values('PID', ascending=False))\n",
    "\n",
    "# Create 'Fence Exists'\n",
    "binaryNullWhereClauseReplacement('Fence')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fireplace Qu\n",
    "\n",
    "We use the same approach as Pools for Fireplaces.\n",
    "\n",
    "First check that number of houses with a Fireplace Quality not null is equal to the number of houses with a number of Fireplace above 0.\n",
    "\n",
    "As it is the case, then create a 'Fireplace Exist' to distinguish houses with at least one fireplace.\n",
    "\n",
    "Regarding the Fireplace Quality column, documentation says that it's an ordinal column. Instead of doing a one-hot encoding, let's replace values in that column with numeric values representing the ordinal classification of firaplace quality.\n",
    "\n",
    "> Note: We define a function to modify ordinal string encoding by numeric values, as we will repeat this operation later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of houses with fireplace quality evaluation:\t 2430\n",
      "Number of houses with at least one fireplace:\t\t 1244\n",
      "Doing a binary replacement on Train Dataset [Fireplace Qu]\n",
      "New column name: Fireplace Qu Exists\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "WARNING: binaryNullWhereClauseReplacement found number of values != 2. Aborting Notebook execution",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m WARNING: binaryNullWhereClauseReplacement found number of values != 2. Aborting Notebook execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Ensure that number of houses without a pool is in line with the poll size information (only houses with\n",
    "# a pool should have a pool area above 0)\n",
    "print(\"Number of houses with fireplace quality evaluation:\\t\",data_df.shape[0] - data_df['Fireplace Qu'].isnull().sum())\n",
    "print(\"Number of houses with at least one fireplace:\\t\\t\",data_df[data_df['Fireplaces'] > 0]['Fireplaces'].count())\n",
    "\n",
    "# Replace null values in 'Pool QC' by 0, non null by 1, keep original column\n",
    "binaryNullWhereClauseReplacement('Fireplace Qu', drop_original_column=False)\n",
    "# data_df['Fireplace Exists'] = np.where(data_df['Fireplace Qu'].isnull(), 'no', 'yes')\n",
    "# addColumnToOneHotEncoding(['Fireplace Exists'])\n",
    "\n",
    "\n",
    "# Function definition to rencode ordinal column to numerical \n",
    "def encodeOrdinalColumnToNumeric(df, column, mapping={}, replacena= None, inplace=True):\n",
    "    \"\"\"\n",
    "    This function replaces values in column passed as parameter using the mapping dict provided.\n",
    "    Key of the dict are used as search value in cells, and if match, cell value is replace by the value\n",
    "    of mapping[key]\n",
    "    replacena parameter, if different from None is used as replacement of null values\n",
    "    Inplace parameter is used to perform changes directly on the dataframe passed as parameter or a copy of it\n",
    "    Whatever the value of inplace parameter, the modified dataframe is returned by ther function\n",
    "    Note that dtype of modified column is automatically set to int64 if all values have been replaced with numeric one\n",
    "    Function also prints the unique values found in the column after transformation. This information could be used\n",
    "    to validate that we've not missed any replacement.\n",
    "    We do also ensure that column received is not a numeric one (our algorythm won't work otherwise). if it is, then\n",
    "    the function simply returns the original dataframe.\n",
    "    \"\"\"\n",
    "    if(not inplace):\n",
    "        df = df.copy()\n",
    "    \n",
    "    # is the column numeric\n",
    "    if pd.api.types.is_numeric_dtype(df[column].dtype):\n",
    "        # yes, return df\n",
    "        print(\"Column is already numerical. Nothing to do.\")\n",
    "        return df\n",
    "\n",
    "    # replace null values\n",
    "    if replacena != None:\n",
    "        df.loc[df[column].isnull(), column] = replacena\n",
    "    # replace values using mapping\n",
    "    for key in mapping:\n",
    "        df.loc[df[column] == key, column] = mapping[key]\n",
    "        \n",
    "    # Do an exit(1) if resulting column is not a numeric one\n",
    "    if pd.api.types.is_numeric_dtype(df[column].dtype) == False:\n",
    "        raise SystemExit(\"WARNING: encodeOrdinalColumnToNumeric returns a non numerical column. Aborting Notebook execution\")\n",
    "    else:\n",
    "        print(\"Column successfully encoded with numerical values\")\n",
    "    print(\"Values in column:\", df[column].unique())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Re-encode column\n",
    "print(\"Convert Ordinal column to numerical\")\n",
    "fireplace_mapping = { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 }\n",
    "encodeOrdinalColumnToNumeric(data_df, column='Fireplace Qu', mapping=fireplace_mapping, replacena=0).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode and drop columns identified previously\n",
    "\n",
    "It's now time to 'one-hot' encode and drop identified columns above using our function dropAndEncode() defined above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataframe: Train Dataset\n",
      "  Do 'one-hot' encoding on: {'Alley Type', 'Misc Feature'}\n",
      "  Drop columns: {'Pool QC', 'Fence', 'PID', 'Alley', 'Order'}\n",
      "Working on dataframe: Test Dataset\n",
      "  Do 'one-hot' encoding on: {'Alley Type', 'Misc Feature'}\n",
      "  Drop columns: {'Pool QC', 'Fence', 'PID', 'Alley', 'Order'}\n"
     ]
    }
   ],
   "source": [
    "dropAndEncode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove lines with empty cells on columns with a few empty values\n",
    "\n",
    "Some of the remaining column after this first cleaning still contains empty cells. Decision is made to drop all the lines that contains null values in the columns where the total number of null values in those columns is not null and lower than a fixed value.\n",
    "\n",
    "To evaluate the fixed value, we will try different one and maesure how much line will be dropped. If the result is less the 20%, then it's a good choice. 20% of the test dataframe represents around 80% of the test dataset, which is an acceptable factor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting size of the Dataframe (factor =  10) = 2426/2430 (ratio = 99.84%)\n",
      "Resulting size of the Dataframe (factor = 100) = 2333/2430 (ratio = 96.01%)\n",
      "Resulting size of the Dataframe (factor = 200) = 2209/2430 (ratio = 90.91%)\n",
      "Resulting size of the Dataframe (factor = 300) = 2209/2430 (ratio = 90.91%)\n",
      "Resulting size of the Dataframe (factor = 400) = 2209/2430 (ratio = 90.91%)\n",
      "Resulting size of the Dataframe (factor = 500) = 1815/2430 (ratio = 74.69%)\n"
     ]
    }
   ],
   "source": [
    "# Sum number of empty cells per column\n",
    "null_sum_df = data_df.isnull().sum().to_frame()\n",
    "\n",
    "# A dictionnary that will contain the different dataframe\n",
    "data_df_list = dict()\n",
    "\n",
    "for i in (10, 100, 200, 300, 400, 500):\n",
    "    columns_df = null_sum_df[np.logical_and(null_sum_df[0] > 0, null_sum_df[0] < i)]\n",
    "    bool_filter = data_df[columns_df.index.values.tolist()].isnull().values.any(axis=1)\n",
    "    data_df_list[i] = data_df[np.logical_not(bool_filter)]\n",
    "    df_size = data_df_list[i].shape[0]\n",
    "    print(\"Resulting size of the Dataframe (factor = {:3}) = {}/{} (ratio = {:.2f}%)\".format(i,df_size,data_df.shape[0],(df_size/data_df.shape[0])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our previous test, if we drop all the lines where, in the corresponding columns, the number of empty cells are not null and below 400, we do remove around 200 lines, which is acceptable. Our dataframe should now take the value data_df_list[400].\n",
    "\n",
    "And finally, we remain with only one column containing null values: Lot Frontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pool QC</th>\n",
       "      <td>2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misc Feature</th>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley Type</th>\n",
       "      <td>2067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "Pool QC       2198\n",
       "Misc Feature  2129\n",
       "Alley Type    2067"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df_list[400].copy()\n",
    "\n",
    "# Display columns with empty values, sorted descending\n",
    "data_df.isnull().sum().to_frame().sort_values(0, ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at thisd column to determine what to do with empty cells.\n",
    "\n",
    "Best option at that time, draw an histogram graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['Lot Frontage'].plot.hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous graph shows that we have some outliers in this columns, and most of the datapoints are centered on a value around 60.\n",
    "\n",
    "The approach we can choose to handle null values in this column is to replace them by the mean value of the column, without the outliers and null values. See below the new histogram and the mean value calculated. This value will be used to replace null values in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value calculated with the reduced dataset: 68.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['Lot Frontage'][np.logical_and(data_df['Lot Frontage'] < 150, data_df['Lot Frontage'] > 0)].plot.hist(bins=20)\n",
    "mean_value = data_df['Lot Frontage'][np.logical_and(data_df['Lot Frontage'] < 150, data_df['Lot Frontage'] > 0)].mean()\n",
    "print(\"Mean value calculated with the reduced dataset: {:.2f}\".format(mean_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null value in dataframe: 10215\n",
      "Dataframe size: (2209, 87)\n",
      "Good :-)\n"
     ]
    }
   ],
   "source": [
    "data_df['Lot Frontage Clean'] = data_df['Lot Frontage'].fillna(int(mean_value))\n",
    "\n",
    "# do not forget to drop the orignal column\n",
    "data_df = data_df.drop('Lot Frontage', axis=1)\n",
    "\n",
    "print(\"Number of null value in dataframe:\", data_df.isnull().sum().sum())\n",
    "print(\"Dataframe size:\", data_df.shape)\n",
    "print(\"Good :-)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine. Our dataset has now 0 null values. It's time now to perform feature encoding and feature engineering \n",
    "\n",
    "Before that, let's classify columns in four categories using the documentation provided with the dataset. Goal is to build 4 list of column names, one for each type: continuous, nominal, ordinal and discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of column not classified: 12\n",
      "Column names: Alley Exists,Alley Type,Fence,Fireplace Exists,Fireplace Qu,Has Fence,Misc Feature,Order,PID,Pool,Pool QC,Utilities\n"
     ]
    }
   ],
   "source": [
    "# Continuous variables\n",
    "continuous_column = [\n",
    "    '1st Flr SF', '2nd Flr SF', 'Lot Frontage Clean', 'Lot Area', 'Mas Vnr Area', 'Bsmt Unf SF', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Total Bsmt SF',\n",
    "    'Low Qual Fin SF', 'Gr Liv Area', 'Garage Area', '3Ssn Porch', 'Open Porch SF', 'Wood Deck SF', 'Pool Area', 'Screen Porch', 'Misc Val', 'Enclosed Porch',\n",
    "]\n",
    "\n",
    "# Nominal variables - no possible ordering\n",
    "nominal_column = [\n",
    "    'MS SubClass', 'MS Zoning', 'Street', 'Land Contour', 'Lot Config', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Exterior 1st',\n",
    "    'Exterior 2nd', 'Roof Matl', 'Roof Style', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', 'Sale Condition', 'Sale Type', 'Street', 'Alley',\n",
    "]\n",
    "\n",
    "# Ordinal variables - you can order the categories\n",
    "ordinal_column =[\n",
    "    'Lot Shape', 'Land Slope', 'Overall Cond', 'Overall Qual', 'Exter Cond', 'Exter Qual', 'Bsmt Cond', 'Bsmt Qual', 'Bsmt Exposure', 'BsmtFin Type 1',\n",
    "    'BsmtFin Type 2', 'Heating QC', 'Electrical', 'Kitchen Qual', 'Functional', 'Garage Finish', 'Garage Cond', 'Garage Qual', 'Paved Drive',\n",
    "]\n",
    "\n",
    "# Discrete variables - categories are integer values\n",
    "discrete_column = [\n",
    "    'Year Built', 'Year Remod/Add', 'Mo Sold', 'Yr Sold', 'Full Bath', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Half Bath', 'TotRms AbvGrd', 'Fireplaces',\n",
    "    'Garage Yr Blt', 'Garage Cars', 'Bedroom AbvGr', 'Kitchen AbvGr',\n",
    "]\n",
    "\n",
    "y_column = [\n",
    " 'SalePrice',\n",
    "]\n",
    "\n",
    "# This trick should return an the columns we've one-hot encoded above, number of these should be 15\n",
    "unclassified_columns = set(data_df.columns.values.tolist()) - set(continuous_column) - set(nominal_column) - set(ordinal_column) - set(discrete_column) - set(y_column)\n",
    "print(\"Number of column not classified:\",len(unclassified_columns))\n",
    "print(\"Column names:\",','.join(sorted(unclassified_columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal columns\n",
    "\n",
    "Let's consider first the ordinal columns, and convert them to numerical column for better model fitting, using our previous encodeOrdinalColumnToNumeric() function.\n",
    "\n",
    "Looking at some of those columns, we must perform some more data cleaning before converting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basement\n",
    "\n",
    "Basement information are contained in 8 Bsmt* columns plus 'Total Bsmt SF'. 5 of them are ordinal:\n",
    "* Bsmt Cond\n",
    "* Bsmt Exposure\n",
    "* Bsmt Qual\n",
    "* BsmtFin Type 1\n",
    "* BsmtFin Type 2\n",
    "\n",
    "We will encode them as numerical column, which will remove null values, and build another column which states if the house has a basement. This new column will be based on the 'Total Bsml SF' column and will be 'one-hot' encoded.\n",
    "\n",
    "Before that, I do a small control to ensure that Total Bsmt SF = Bsmt 1 SF + Bsmt 2 SF + Basmt Unfinished SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True    2209\n",
      "Name: Equal ?, dtype: int64\n",
      "No False result, equality between cells about Square Feet is respected\n"
     ]
    }
   ],
   "source": [
    "temp_df = data_df[['Total Bsmt SF','Bsmt Unf SF','Bsmt Cond','Bsmt Exposure','Bsmt Qual','BsmtFin Type 1','BsmtFin Type 2','BsmtFin SF 1','BsmtFin SF 2']].copy()\n",
    "temp_df['Sum'] = data_df['BsmtFin SF 1'] + data_df['BsmtFin SF 2'] + data_df['Bsmt Unf SF']\n",
    "temp_df['Equal ?'] = temp_df['Sum'] == temp_df['Total Bsmt SF']\n",
    "print(temp_df['Equal ?'].value_counts())\n",
    "print(\"No False result, equality between cells about Square Feet is respected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing is the ordinal value 'Unf' in 'BsmtFin Type 1' and 'BsmFin Type 2'. This value does not evaluate the quality of the basement but the fact that it is not finished.\n",
    "\n",
    "I will then create two new columns 'Bsmt Type 1 Unf' and 'Bsmt Type 2 Unf' with yes or no value, and ont hot encode those. Then, on the BsmtFin Type 1 & 2 column, I will replace 'Unf' values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be one-hot encoded': Bsmt Type 1 Unf,Bsmt Exists,Bsmt Type 2 Unf\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [4 3 5 2 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 4 2 5 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [1 3 2 4]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [5 0 2 1 3 4]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [0 1 3 2 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Create Basement Exists, Bsmt Type 1 & 2 Unf and one encode them\n",
    "data_df['Bsmt Exists'] = np.where(data_df['Total Bsmt SF'] == 0, 'no', 'yes')\n",
    "data_df['Bsmt Type 1 Unf'] = np.where(data_df['BsmtFin Type 1'] == 'Unf', 'yes', 'no')\n",
    "data_df['Bsmt Type 2 Unf'] = np.where(data_df['BsmtFin Type 2'] == 'Unf', 'yes', 'no')\n",
    "addColumnToOneHotEncoding(['Bsmt Exists', 'Bsmt Type 1 Unf','Bsmt Type 2 Unf'])\n",
    "ordinal_column.extend(['Bsmt Exists', 'Bsmt Type 1 Unf','Bsmt Type 2 Unf'])\n",
    "\n",
    "\n",
    "# Convert ordinal Bsmt columns to numerical\n",
    "mapping = {\n",
    "    'Bsmt Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Bsmt Cond': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Bsmt Exposure': { 'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1 },\n",
    "    'BsmtFin Type 1': { 'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0 },\n",
    "    'BsmtFin Type 2': { 'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0 },\n",
    "}\n",
    "for c in mapping:\n",
    "    encodeOrdinalColumnToNumeric(data_df, column=c, mapping=mapping[c], replacena=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities\n",
    "\n",
    "The 'Utilities' ordinal column is a bit special as all but three entries are identical. This let me think that this information is really not usefull to fit a model.\n",
    "\n",
    "Instead of dropping this columns, I would prefer to drop the three lines that are different from the rest. This will avoid having outliers in our train dataset for house sale prices as these three houses do not have all the basic utilities. Furthermode, a look at the test dataset shows that we do have only houses in this 500 lines dataset with all the Utilities. Loosing information on how much incomplete utilities can modify the sale price is useless here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing values in 'Utilities' column of the test dataset is unique:\n",
      "AllPub    500\n",
      "Name: Utilities, dtype: int64\n",
      "We can drop the 'Utilities' and column from the train dataset and remove the three houses\n",
      "Columns flaged as 'to be removed': Utilities\n"
     ]
    }
   ],
   "source": [
    "print(\"Existing values in 'Utilities' column of the test dataset is unique:\")\n",
    "print(test_df['Utilities'].value_counts())\n",
    "print(\"We can drop the 'Utilities' and column from the train dataset and remove the three houses\")\n",
    "\n",
    "# Remove the three houses that do not have all the utilities\n",
    "data_df = data_df[data_df['Utilities'] == 'AllPub']\n",
    "addColumnToDropList(['Utilities'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garage\n",
    "\n",
    "Garage is nearly the same as for Basement. Some of the houses do not have garage.\n",
    "\n",
    "Best way shoulod be to create a new column 'Has Garage' and convert ordinal Garage columns to numerical values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns flaged as 'to be one-hot encoded': Bsmt Type 1 Unf,Bsmt Exists,Bsmt Type 2 Unf,Has Garage\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 1 2]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 2 4 5 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 2 4 5 1]\n"
     ]
    }
   ],
   "source": [
    "# Create Has Garasge and one encode it\n",
    "data_df['Has Garage'] = np.where(data_df['Garage Area'] == 0, 'no', 'yes')\n",
    "addColumnToOneHotEncoding(['Has Garage'])\n",
    "\n",
    "# Convert ordinal Garage columns to numerical\n",
    "mapping = {\n",
    "    'Garage Finish': {'Fin': 3, 'RFn': 2, 'Unf': 1 },\n",
    "    'Garage Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Garage Cond': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "}\n",
    "\n",
    "for c in mapping:\n",
    "    encodeOrdinalColumnToNumeric(data_df, column=c, mapping=mapping[c], replacena=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining ordinal columns\n",
    "\n",
    "The remaining ordinal columns are simply re-encoded using numerical values, except for 'Overall Cond' and 'Overall Qual' as those two columns are already ordinal ones with numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column successfully encoded with numerical values\n",
      "Values in column: [5 3 4 2 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 4 2 5 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [4 3 2 5]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [8 5 4 6 7 3 2]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [5 3 2 4 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [4 3 5 2 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 2 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 4 2 1]\n",
      "Column successfully encoded with numerical values\n",
      "Values in column: [3 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "    'Electrical': { 'SBrkr': 5, 'FuseA': 4,'FuseF': 3,'FuseP': 2, 'Mix': 1 },\n",
    "    'Exter Cond': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Exter Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Functional': { 'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 0 },\n",
    "    'Heating QC': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Kitchen Qual': { 'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1 },\n",
    "    'Land Slope': { 'Gtl': 3, 'Mod': 2, 'Sev': 1 },\n",
    "    'Lot Shape': { 'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1 },\n",
    "    'Paved Drive': { 'Y': 3, 'P': 2, 'N': 1 },\n",
    "}\n",
    "\n",
    "for c in mapping:\n",
    "    encodeOrdinalColumnToNumeric(data_df, column=c, mapping=mapping[c], replacena=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up\n",
    "\n",
    "Now that all our ordinal column have been transformed and/or re-encoded, let's drop and one-hot encode the columns and check that our ordinal columns of our dataframe are all dtype = numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Bsmt Type 1 Unf', 'Bsmt Exists', 'Bsmt Type 2 Unf'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4e21c8d3aad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolumns_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mordinal_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loc'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Bsmt Type 1 Unf', 'Bsmt Exists', 'Bsmt Type 2 Unf'] not in index\""
     ]
    }
   ],
   "source": [
    "data_df= pd.get_dummies(data_df, columns=columns_to_encode)\n",
    "data_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "columns_to_drop = set()\n",
    "columns_to_encode = set()\n",
    "\n",
    "data_df[ordinal_column].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data_df.select_dtypes(np.number):\n",
    "    c_mean = data_df[c].mean()\n",
    "    c_std  = data_df[c].std()\n",
    "    z_min  = (c_mean-data_df[c].min())/c_std\n",
    "    z_max  = (data_df[c].max()-c_mean)/c_std\n",
    "    outliers = ''\n",
    "    if (z_min > 2 or z_max > 2):\n",
    "        outliers = '(outliers)'\n",
    "    #print(\"Column {:20s} mean:{:9.2f}\\tstd:{:9.2f}\\tz-min:{:9.2f}\\tz-max:{:10.2f} {}\".format(c, c_mean, c_std, z_min, z_max, outliers))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Pool Area'].sort_values(ascending=False)\n",
    "temp_df = data_df[data_df['Pool Area'] > 0]\n",
    "plt.scatter(temp_df['Pool Area'], temp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "data_df[continuous_column].hist(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding\n",
    "\n",
    "> Question: What is the difference between feature encoding and feature engineering ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communicating the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

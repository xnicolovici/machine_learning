{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project No 3 - Part 2 - House prices - 2 of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import base libraries\n",
    "\n",
    "Let's import all the base libraries that we will use in this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "In this Notebook, we will load the cleaned and adapted version of our two datasets. See introduction in the Notebook *house-prices-solution-1-of-2.ipynb* to know form where those files arise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset: (2207, 242)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Condition 1_RRNn</th>\n",
       "      <th>House New</th>\n",
       "      <th>Extra Flr SF Exists</th>\n",
       "      <th>2nd Flr SF Exists</th>\n",
       "      <th>Low Qual Fin SF Exists</th>\n",
       "      <th>3Ssn Porch Exists</th>\n",
       "      <th>Misc Val Exists</th>\n",
       "      <th>Enclosed Porch Exists</th>\n",
       "      <th>Screen Porch Exists</th>\n",
       "      <th>Continuous Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528275070</td>\n",
       "      <td>8795</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535305120</td>\n",
       "      <td>10170</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>923228250</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID  Lot Area  Lot Shape  Land Slope  Overall Qual  Overall Cond  \\\n",
       "0  528275070      8795          3           3             7             5   \n",
       "1  535305120     10170          4           3             6             6   \n",
       "2  923228250      2001          4           3             4             5   \n",
       "\n",
       "   Year Built  Year Remod/Add  Exter Qual  Exter Cond  ...  Condition 1_RRNn  \\\n",
       "0          10              10           4           3  ...                 0   \n",
       "1          59              59           3           3  ...                 0   \n",
       "2          40              40           3           3  ...                 0   \n",
       "\n",
       "   House New  Extra Flr SF Exists  2nd Flr SF Exists  Low Qual Fin SF Exists  \\\n",
       "0          0                    0                  1                       0   \n",
       "1          0                    0                  0                       0   \n",
       "2          0                    0                  1                       0   \n",
       "\n",
       "   3Ssn Porch Exists  Misc Val Exists  Enclosed Porch Exists  \\\n",
       "0                  0                0                      0   \n",
       "1                  0                0                      0   \n",
       "2                  0                0                      0   \n",
       "\n",
       "   Screen Porch Exists  Continuous Sum  \n",
       "0                    0           346.0  \n",
       "1                    0           597.0  \n",
       "2                    0           101.0  \n",
       "\n",
       "[3 rows x 242 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join('data','house-prices-cleaned.csv'))\n",
    "\n",
    "print(\"Size of the train dataset:\", train_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the test dataset: (500, 242)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Condition 1_RRNn</th>\n",
       "      <th>House New</th>\n",
       "      <th>Extra Flr SF Exists</th>\n",
       "      <th>2nd Flr SF Exists</th>\n",
       "      <th>Low Qual Fin SF Exists</th>\n",
       "      <th>3Ssn Porch Exists</th>\n",
       "      <th>Misc Val Exists</th>\n",
       "      <th>Enclosed Porch Exists</th>\n",
       "      <th>Screen Porch Exists</th>\n",
       "      <th>Continuous Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909279080</td>\n",
       "      <td>11275</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>907126050</td>\n",
       "      <td>9757</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528144030</td>\n",
       "      <td>11065</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID  Lot Area  Lot Shape  Land Slope  Overall Qual  Overall Cond  \\\n",
       "0  909279080     11275          3           2             6             7   \n",
       "1  907126050      9757          4           2             5             7   \n",
       "2  528144030     11065          3           3             8             5   \n",
       "\n",
       "   Year Built  Year Remod/Add  Exter Qual  Exter Cond  ...  Condition 1_RRNn  \\\n",
       "0          78              60           3           3  ...                 0   \n",
       "1          16              16           3           4  ...                 0   \n",
       "2           4               4           4           3  ...                 0   \n",
       "\n",
       "   House New  Extra Flr SF Exists  2nd Flr SF Exists  Low Qual Fin SF Exists  \\\n",
       "0          0                    0                  1                       0   \n",
       "1          0                    0                  0                       0   \n",
       "2          1                    0                  1                       0   \n",
       "\n",
       "   3Ssn Porch Exists  Misc Val Exists  Enclosed Porch Exists  \\\n",
       "0                  0                0                      1   \n",
       "1                  0                0                      0   \n",
       "2                  0                0                      0   \n",
       "\n",
       "   Screen Porch Exists  Continuous Sum  \n",
       "0                    0           548.0  \n",
       "1                    1           131.0  \n",
       "2                    0          1125.0  \n",
       "\n",
       "[3 rows x 242 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join('data','house-prices-test-cleaned.csv'))\n",
    "\n",
    "print(\"Size of the test dataset:\", test_df.shape)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so here we are, cleaned Train and adapted Test datasets ready for machine learning work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "In order to fit different models and evaluate them, we have to obtain a test set with known 'SalePrice' values.\n",
    "\n",
    "As the Test dataset we have does not include this information (we are seeking for a good model to predict 'SalePrive of the Test dataset), we are forced to build a new train/test dataset from the main TRain dataset. The main Test dataset will be used at the very last of this Notebook when we will try to predict their 'SalePrice'\n",
    "\n",
    "So, first thing to do, build an train/test dataset based on 80%/20% randomly selected rows from the main Train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature matrix and vector result\n",
    "\n",
    "We have to fit three models: a simple, an intermediate and a complex one.\n",
    "\n",
    "Difference between those models are the number of feature we consider to fit the model.\n",
    "\n",
    "    * Simple model: Use 3 features from dataset\n",
    "    * Intermediate model: Use 15 features from dataset\n",
    "    * Complex model: Use all features\n",
    "    \n",
    "I've decided to use the *SelectKBest* to build the simple and intermediate feature matrix.\n",
    "\n",
    "> Note: Variables and results for the three different models will be stored into a dict() named *model_results*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_NB_FEATURE=3\n",
    "MEDIUM_NB_FEATURE=15\n",
    "\n",
    "model_results = {\n",
    "    'small': {\n",
    "        'name': 'simple model',\n",
    "        'filename': 'predictions-simple-model.csv',\n",
    "    },\n",
    "    'medium': {\n",
    "        'name': 'intermediate model',\n",
    "        'filename': 'predictions-intermediate-model.csv',\n",
    "    },\n",
    "    'full': {\n",
    "        'name': 'complex model',\n",
    "        'filename': 'predictions-complex-model.csv',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build datasets, feature matrix and result vector for the complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: full\n",
      "  Shape of X_tr variable: (1765, 240)\n",
      "  Shape of y_tr variable: (1765,)\n",
      "  Shape of X_te variable: (442, 240)\n",
      "  Shape of y_te variable: (442,)\n",
      "  Shape of X variable   : (2207, 240)\n",
      "  Shape of y variable   : (2207,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constant used to split main Train dataset in two train/test datasets\n",
    "TRAIN_SIZE=0.8\n",
    "RANDOM_STATE=0\n",
    "\n",
    "\n",
    "# Function used to build feature matrix and result vector\n",
    "def buildDataMatrix(model_results, model_name, df=train_df):\n",
    "    \"\"\"\n",
    "    This function is used to build feature matrix and result vector.\n",
    "    It expect as first parameter the global dict variable to store the result.\n",
    "    Second parameter is the name of the model, and the third is the dataframe to\n",
    "    use (default is train_df).\n",
    "    \"\"\"\n",
    "    # Split data in two dataframe: complex model\n",
    "    # Based on the full featured train_df dataset\n",
    "    tr_df, te_df = train_test_split(df, test_size = 1-TRAIN_SIZE, train_size=TRAIN_SIZE, random_state=RANDOM_STATE)\n",
    "    # Build feature matrix X and result vector y narray from the train and test dataframe\n",
    "    model_results[model_name]['X_tr'] = tr_df.drop(['SalePrice','PID'], axis=1, errors='ignore').values\n",
    "    model_results[model_name]['y_tr'] = tr_df.SalePrice.values\n",
    "    model_results[model_name]['X_te'] = te_df.drop(['SalePrice','PID'], axis=1, errors='ignore').values\n",
    "    model_results[model_name]['y_te'] = te_df['SalePrice'].values\n",
    "\n",
    "    model_results[model_name]['X'] = np.concatenate((model_results[model_name]['X_tr'], model_results[model_name]['X_te']))\n",
    "    model_results[model_name]['y'] = np.concatenate((model_results[model_name]['y_tr'], model_results[model_name]['y_te']))\n",
    "    \n",
    "    model_results[model_name]['features'] = tr_df.drop(['SalePrice','PID'], axis=1, errors='ignore').columns\n",
    "    model_results[model_name]['result']   = 'SalePrice'\n",
    "\n",
    "    \n",
    "    print(\"Model:\", model_name)\n",
    "    print(\"  Shape of X_tr variable:\".format(model_name), model_results[model_name]['X_tr'].shape)\n",
    "    print(\"  Shape of y_tr variable:\",model_results[model_name]['y_tr'].shape)\n",
    "\n",
    "    print(\"  Shape of X_te variable:\",model_results[model_name]['X_te'].shape)\n",
    "    print(\"  Shape of y_te variable:\",model_results[model_name]['y_te'].shape)\n",
    "\n",
    "    print(\"  Shape of X variable   :\",model_results[model_name]['X'].shape)\n",
    "    print(\"  Shape of y variable   :\",model_results[model_name]['y'].shape)\n",
    "    \n",
    "buildDataMatrix(model_results, 'full')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SelectKBest to build the small and medium datasets\n",
    "\n",
    "I use a trick to retrieve the dataset column name selected by the *SelectKBest* model.\n",
    "\n",
    "    > [https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 'small' with 3 selected using SelectKBest\n",
      "  Feature selected: ['Overall Qual', 'Year Built', 'Gr Liv Area']\n",
      "Model: small\n",
      "  Shape of X_tr variable: (1765, 3)\n",
      "  Shape of y_tr variable: (1765,)\n",
      "  Shape of X_te variable: (442, 3)\n",
      "  Shape of y_te variable: (442,)\n",
      "  Shape of X variable   : (2207, 3)\n",
      "  Shape of y variable   : (2207,)\n",
      "Build model 'medium' with 15 selected using SelectKBest\n",
      "  Feature selected: ['Overall Qual', 'Year Built', 'Year Remod/Add', 'Exter Qual', 'Bsmt Qual', 'Total Bsmt SF', '1st Flr SF', 'Gr Liv Area', 'Full Bath', 'Kitchen Qual', 'Garage Yr Blt', 'Garage Cars', 'Garage Area', 'Fireplace Quality', 'Continuous Sum']\n",
      "Model: medium\n",
      "  Shape of X_tr variable: (1765, 15)\n",
      "  Shape of y_tr variable: (1765,)\n",
      "  Shape of X_te variable: (442, 15)\n",
      "  Shape of y_te variable: (442,)\n",
      "  Shape of X variable   : (2207, 15)\n",
      "  Shape of y variable   : (2207,)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for SlectKBest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Build data for the two models\n",
    "for model_name, nb_feature in zip(['small', 'medium'],[SMALL_NB_FEATURE, MEDIUM_NB_FEATURE]):\n",
    "    \n",
    "    print(\"Build model '{}' with {} selected using SelectKBest\".format(model_name,nb_feature))\n",
    "    \n",
    "    # Create SelectKBest instance using 'chi2' score function\n",
    "    select = SelectKBest(mutual_info_regression, k=nb_feature)\n",
    "    \n",
    "    # fit the model with models['complex'] (full feature)\n",
    "    select.fit(model_results['full']['X'], model_results['full']['y'])\n",
    "    \n",
    "    # Get a mask of the feature selected\n",
    "    mask = select.get_support() #list of booleans\n",
    "    \n",
    "    # Retrieve feature names\n",
    "    features = []\n",
    "    for bool, feature in zip(mask, model_results['full']['features']):\n",
    "        if bool:\n",
    "            features.append(feature)\n",
    "\n",
    "    print(\"  Feature selected:\", features)\n",
    "    features.append('SalePrice')\n",
    "\n",
    "    \n",
    "    \n",
    "    buildDataMatrix(model_results, model_name, df=train_df[features])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed libraries and create Pipelines instances\n",
    "\n",
    "I've decided to test Ridge and Huber regressor on the three models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'huber': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('estimator', HuberRegressor())\n",
    "        ]),\n",
    "    'ridge': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('estimator', Ridge())\n",
    "        ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit pipeline models to the three datasets\n",
    "\n",
    "The following function uses the pippelines to fit models on our three dataset.\n",
    "\n",
    "At the end ot the work, it adds a baseline estimator which uses the mean values of the test result vector as result prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/xavier/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/xavier/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/xavier/anaconda3/envs/exts-ml/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in power\n",
      "  del sys.path[0]\n",
      "/home/xavier/anaconda3/envs/exts-ml/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in power\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e85629ccc836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mfitModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e85629ccc836>\u001b[0m in \u001b[0;36mfitModels\u001b[0;34m(model_results, pipelines)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Get MAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mmae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_te'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Store best model information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 170\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m~/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit estimator with our defined pipelines\n",
    "\n",
    "def fitModels(model_results=model_results, pipelines=pipelines):\n",
    "    smallest_mae = None\n",
    "    best_model = None\n",
    "    for model_name in model_results.keys():\n",
    "        model_results[model_name]['regression'] = {}\n",
    "        for pipeline_name in pipelines.keys():\n",
    "            # fit model Ridge with outliers\n",
    "            pipelines[pipeline_name].fit(model_results[model_name]['X_tr'], model_results[model_name]['y_tr'])\n",
    "\n",
    "            # predict values\n",
    "            y_pred=10**pipelines[pipeline_name].predict(model_results[model_name]['X_te'])\n",
    "    \n",
    "            # Get MAE\n",
    "            mae=MAE(10**model_results[model_name]['y_te'], y_pred)\n",
    "            \n",
    "            # Store best model information\n",
    "            if (smallest_mae == None) or (smallest_mae > mae):\n",
    "                smallest_mae=mae\n",
    "                best_model=(model_name, pipeline_name)\n",
    "    \n",
    "            # store value in global dict\n",
    "            model_results[model_name]['regression'][pipeline_name] = {\n",
    "                'y_pred': y_pred,\n",
    "                'mae': mae,\n",
    "            }\n",
    "\n",
    "            print(\"MAE with {} regressor and outliers on {} model: {:.2f}\".format(pipeline_name, model_name, mae))\n",
    "            \n",
    "    print(\"\\n => Best model is {} on {} dataset\".format(best_model[1], best_model[0]))\n",
    "    \n",
    "    y_pred_mean=np.full(model_results['full']['y_te'].shape[0], model_results['full']['y_te'].mean())\n",
    "\n",
    "    # Add baseline to our global dict\n",
    "    model_results['full']['regression']['baseline'] = {\n",
    "        'mae': MAE(10**model_results['full']['y_te'], 10**y_pred_mean)\n",
    "    } \n",
    "    return\n",
    "\n",
    "            \n",
    "fitModels()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Right. We've found that the best results are obtained using HuberRegressor on the full dataset using default parameters.\n",
    "\n",
    "Let's now try to find the optimum parameters to improve our model. We will do this in two manner. First approach, the simlest one, we will try different values of the *espilon* parameter and seek for the best MAE result. Second approach, we will use the *GridSearchCV* class from sklearn. \n",
    "\n",
    "> Note: Regularization will be done on the full dataset as it is with it that we obtain the best results so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a range of *epsilon* values\n",
    "\n",
    "Build a *gs_result* list that will contain, for a range of epsilon values from 1.0 to 1.35, the mean average value of the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variable to store the results\n",
    "gs_results = []\n",
    "\n",
    "# Grid search\n",
    "for alpha in np.logspace(-10, 10, num=50):\n",
    "#for alpha in np.linspace(1.0, 1.35, num=20):\n",
    "    model='huber'\n",
    "    # Create and fit ridge regression\n",
    "    #pipelines[model].set_params(**{'ridge__alpha': alpha})\n",
    "    pipelines['huber'].set_params(**{'estimator__alpha': alpha})\n",
    "    \n",
    "    pipelines[model].fit(model_results['full']['X_tr'], model_results['full']['y_tr'])\n",
    "    #pipelines['huber'].fit(models['complex']['X_tr'], models['complex']['y_tr'])\n",
    "    \n",
    "    # Save model and its performance on train/test sets\n",
    "    gs_results.append({\n",
    "        'alpha': alpha,\n",
    "        'train_mae': MAE(10**model_results['full']['y_tr'], 10**pipelines[model].predict(model_results['full']['X_tr'])),\n",
    "        'test_mae': MAE(10**model_results['full']['y_te'], 10**pipelines[model].predict(model_results['full']['X_te'])),\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "gs_results = pd.DataFrame(gs_results)\n",
    "gs_results.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results found above, search for the best MAE and plot the MAE found for the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entry with the best test MAE\n",
    "best_result = gs_results.loc[gs_results.test_mae.idxmin()]\n",
    "\n",
    "# Print the details\n",
    "print('Best alpha: {:.5f}'.format(best_result.alpha))\n",
    "print('Train MAE: {:,.0f}$'.format(best_result.train_mae))\n",
    "print('Test MAE: {:,.0f}$'.format(best_result.test_mae))\n",
    "\n",
    "# Plot the validation curves\n",
    "#plt.plot(gs_results['alpha'], gs_results['train_mae'], label='train curve')\n",
    "#plt.plot(gs_results['alpha'], gs_results['test_mae'], label='test curve')\n",
    "plt.plot(np.log10(gs_results['alpha']), gs_results['train_mae'], label='train curve')\n",
    "plt.plot(np.log10(gs_results['alpha']), gs_results['test_mae'], label='test curve')\n",
    "\n",
    "plt.scatter(np.log10(best_result.alpha), best_result.test_mae, marker='x', c='red', zorder=10)\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearchCV to test a bunch of parameters\n",
    "\n",
    "Epsilon value is one of the parameters of the HuberRegressor. Should we found best results if we try different values for the others parameters: max_iter, alpha and tol.\n",
    "\n",
    "Instead of writing nested *for loops* to try different combinations, let's use the GreadSearchCV class. This class simply tries all the combination of parameters we'd like to test and calculate for each combination the score it makes.\n",
    "\n",
    "> Note: GreadSearchCV use a KFold approach to select the train and test data from the main dataset. Let's then use the train_df full dataset to feed our GridSearcCV onbject. More on KFlod here: https://machinelearningmastery.com/k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "params = {\n",
    "    'estimator__epsilon': [1.0, 1.1, 1.2],\n",
    "    'estimator__alpha': np.logspace(-10, 10, num=50)\n",
    "}\n",
    "\n",
    "# Define scorer parameter\n",
    "#score = make_scorer(mean_absolute_error)\n",
    "#score=make_scorer(MAE, greater_is_better=False )\n",
    "score=make_scorer(r2_score)\n",
    "\n",
    "\n",
    "\n",
    "gridsearch=GridSearchCV(pipelines['huber'], params, scoring=score, return_train_score=False, cv=5)\n",
    "gridsearch.fit(model_results['full']['X'], model_results['full']['y'])\n",
    "\n",
    "grid_df=pd.DataFrame(gridsearch.cv_results_)[['param_estimator__alpha','param_estimator__epsilon', 'mean_test_score','rank_test_score']]\n",
    "print(gridsearch.best_params_)\n",
    "grid_df.sort_values('mean_test_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['huberX']=gridsearch.best_estimator_\n",
    "\n",
    "fitModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communicating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_SIZE=(20,15)\n",
    "#mae_values = [mae_baseline, mae_lr_all, mae_huber_all, mae_huber_cleaned, mae_lr_cleaned]\n",
    "#mae_labels = ['Baseline w/outliers', 'LR with outliers', 'Huber wizh outliers','Huber w/o outliers', 'LR w/o outliers']\n",
    "\n",
    "mae_values = []\n",
    "mae_labels=[]\n",
    "\n",
    "print(\"MAE results of our different models:\")\n",
    "for model_name in model_results.keys():\n",
    "    for pipeline_name in model_results[model_name]['regression'].keys():\n",
    "        mae_labels.append(\"{} set\\n{} reg.\".format(model_name, pipeline_name))\n",
    "        mae_values.append(model_results[model_name]['regression'][pipeline_name]['mae'])\n",
    "\n",
    "for (label, value) in zip(mae_labels, mae_values):\n",
    "    if value == np.min(mae_values):\n",
    "        smallest = \"(smallest value)\"\n",
    "    else:\n",
    "        smallest = \"\"\n",
    "    print(\"\\t{:35} : {:.2f}   {}\".format(label.replace(\"\\n\",\" - \"), value, smallest))\n",
    "\n",
    "# Bar chart to compare our model\n",
    "plt.figure(figsize=FIGURE_SIZE)\n",
    "plt.bar([i for i in range(1,len(mae_values)+1)], mae_values)\n",
    "plt.xticks([i for i in range(1,len(mae_values)+1)], mae_labels)\n",
    "plt.title('MAE with different regression models')\n",
    "plt.ylabel(\"Mean Average Error in $\")\n",
    "\n",
    "mae_min = np.min(mae_values)\n",
    "plt.plot([0,len(mae_values)+1],[mae_min, mae_min], c='red', label=\"Smallest MAE on Test data = {:.2f} $\".format(mae_min))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_te=test_df.drop(['SalePrice', 'PID'], axis=1).values\n",
    "\n",
    "\n",
    "for model_name in model_results.keys():\n",
    "    print(\"Working with {} ({} dataset)\".format(model_results[model_name]['name'], model_name))\n",
    "\n",
    "    \n",
    "    # Fit model\n",
    "    print(\"Fit model\")\n",
    "    pipelines['huberX'].fit(model_results[model_name]['X_tr'], model_results[model_name]['y_tr'])\n",
    "\n",
    "    # Build test feature matrix\n",
    "    X=test_df[model_results[model_name]['features']]\n",
    "\n",
    "    # Predict result\n",
    "    print(\"Predict values\")\n",
    "    y_pred=np.round(10**pipelines['huberX'].predict(X))\n",
    "    \n",
    "    # Replace 'SalePrice' column values\n",
    "    test_df['SalePrice']=y_pred\n",
    "    \n",
    "    # Save file\n",
    "    filename=model_results[model_name]['filename']\n",
    "    print(\"Save result to\", filename)\n",
    "    test_df[['PID','SalePrice']].to_csv(os.path.join('data',filename), index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the result:\n",
    "    \n",
    "\n",
    "| | Simple model | Intermediate model | Complex model |\n",
    "| :------------- | :----------: | -----------: | -----------: |\n",
    "| MAE (\\$) | \\$ 23,719.41 | \\$ 18,821.62 | \\$ 15,029.44 |\n",
    "| RMSE | 52335.95 | 43417.84 | 41902.92 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

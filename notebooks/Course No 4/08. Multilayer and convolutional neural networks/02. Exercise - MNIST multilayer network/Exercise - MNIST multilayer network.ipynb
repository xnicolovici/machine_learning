{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST multilayer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Load and preprocess data\n",
    "\n",
    "> **Exercise**: Load the MNIST data. Split it into train, validation and test sets. Standardize the images. Define a `get_batches(X, y, batch_size)` function to generate random X/y batches of size `batch_size` using a Python generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: mnist-6k.npz\n"
     ]
    }
   ],
   "source": [
    "# define which xk.npz file to load (give the number of k)\n",
    "number_of_k=6\n",
    "data_filename='mnist-{}k.npz'.format(number_of_k)\n",
    "print('Using file:',data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with np.load(data_filename, allow_pickle=False) as npz_file:\n",
    "    # Load items into a dictionary\n",
    "    mnist = dict(npz_file.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5000, 784) (5000,)\n",
      "Test : (500, 784) (500,)\n",
      "Valid: (500, 784) (500,)\n"
     ]
    }
   ],
   "source": [
    "# Create train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Convert uint8 pixel values to float\n",
    "    mnist['data'].astype(np.float32),\n",
    "    mnist['labels'],\n",
    "    test_size=1000, random_state=0)\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(\n",
    "    # Convert uint8 pixel values to float\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=500, random_state=0)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape, y_test.shape)\n",
    "print(\"Valid:\", X_valid.shape, y_valid.shape)\n",
    "\n",
    "# Rescale train and validation data\n",
    "scaler = StandardScaler()\n",
    "X_train_rescaled = scaler.fit_transform(X_train)\n",
    "X_test_rescaled = scaler.fit_transform(X_test)\n",
    "X_valid_rescaled = scaler.transform(X_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "def get_batches(X, y, batch_size):\n",
    "    # Shuffle X,y\n",
    "    shuffled_idx = np.arange(len(y)) # 1,2,...,n\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "\n",
    "    # Enumerate indexes by steps of batch_size\n",
    "    # i: 0, b, 2b, 3b, 4b, .. where b is the batch size\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        # Batch indexes\n",
    "        batch_idx = shuffled_idx[i:i+batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Create and train a multilayer network\n",
    "\n",
    "> **Exercise:** Create a multilayer neural network and train it using your batch generator. Evaluate the accuracy on the validation set after each epoch. Test different architectures and parameters. Evaluate your best network on the test set. Save the trained weights of the first fully connected layer in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the different networks to try\n",
    "neural_networks={\n",
    "    '2-layer-32': {\n",
    "        'hidden': [32],\n",
    "        'graph': None,\n",
    "    },\n",
    "    '2-layer-64': {\n",
    "        'hidden': [64],\n",
    "        'graph': None,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with network: 2-layer-32\n",
      "  Adding hidden layer with 32 neurons\n",
      "Working with network: 2-layer-64\n",
      "  Adding hidden layer with 64 neurons\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for network_name in neural_networks.keys():\n",
    "    print(\"Working with network:\", network_name)\n",
    "    \n",
    "    # Redefine the graph\n",
    "    neural_networks[network_name]['graph'] = tf.Graph()\n",
    "\n",
    "    with neural_networks[network_name]['graph'].as_default():\n",
    "        # Create placeholders\n",
    "        X = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "        y = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "\n",
    "        for i in neural_networks[network_name]['hidden']:\n",
    "            print('  Adding hidden layer with {} neurons'.format(i))\n",
    "            # Hidden layer with 16 units\n",
    "            hidden = tf.layers.dense(\n",
    "                X, i, activation=tf.nn.relu, # ReLU\n",
    "                kernel_initializer=tf.variance_scaling_initializer(scale=2, seed=0),\n",
    "                bias_initializer=tf.zeros_initializer(),\n",
    "                name='hidden'\n",
    "            )\n",
    "\n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(\n",
    "            hidden, 10, activation=None, # No activation function\n",
    "            kernel_initializer=tf.variance_scaling_initializer(scale=1, seed=0),\n",
    "            bias_initializer=tf.zeros_initializer(),\n",
    "            name='output'\n",
    "        )\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'hidden/kernel:0' shape=(784, 64) dtype=float32_ref>\n",
      "<tf.Variable 'hidden/bias:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'output/kernel:0' shape=(64, 10) dtype=float32_ref>\n",
      "<tf.Variable 'output/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with neural_networks['2-layer-64']['graph'].as_default():\n",
    "    # Get variables in the graph\n",
    "    for v in tf.trainable_variables():\n",
    "        print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Visualize weights\n",
    "\n",
    "> **Exercise**: Plot the weights from the first fully connected layer (the templates) with the `imshow()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

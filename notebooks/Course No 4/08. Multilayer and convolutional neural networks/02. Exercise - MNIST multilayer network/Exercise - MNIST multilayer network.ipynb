{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST multilayer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Load and preprocess data\n",
    "\n",
    "> **Exercise**: Load the MNIST data. Split it into train, validation and test sets. Standardize the images. Define a `get_batches(X, y, batch_size)` function to generate random X/y batches of size `batch_size` using a Python generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: mnist-6k.npz\n"
     ]
    }
   ],
   "source": [
    "# define which xk.npz file to load (give the number of k)\n",
    "number_of_k=6\n",
    "data_filename='mnist-{}k.npz'.format(number_of_k)\n",
    "print('Using file:',data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with np.load(data_filename, allow_pickle=False) as npz_file:\n",
    "    # Load items into a dictionary\n",
    "    mnist = dict(npz_file.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5000, 784) (5000,)\n",
      "Test : (500, 784) (500,)\n",
      "Valid: (500, 784) (500,)\n"
     ]
    }
   ],
   "source": [
    "# Create train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Convert uint8 pixel values to float\n",
    "    mnist['data'].astype(np.float32),\n",
    "    mnist['labels'],\n",
    "    test_size=1000, random_state=0)\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(\n",
    "    # Convert uint8 pixel values to float\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=500, random_state=0)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape, y_test.shape)\n",
    "print(\"Valid:\", X_valid.shape, y_valid.shape)\n",
    "\n",
    "# Rescale train and validation data\n",
    "scaler = StandardScaler()\n",
    "X_train_rescaled = scaler.fit_transform(X_train)\n",
    "X_test_rescaled = scaler.fit_transform(X_test)\n",
    "X_valid_rescaled = scaler.transform(X_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "def get_batches(X, y, batch_size):\n",
    "    # Shuffle X,y\n",
    "    shuffled_idx = np.arange(len(y)) # 1,2,...,n\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "\n",
    "    # Enumerate indexes by steps of batch_size\n",
    "    # i: 0, b, 2b, 3b, 4b, .. where b is the batch size\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        # Batch indexes\n",
    "        batch_idx = shuffled_idx[i:i+batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Create and train a multilayer network\n",
    "\n",
    "> **Exercise:** Create a multilayer neural network and train it using your batch generator. Evaluate the accuracy on the validation set after each epoch. Test different architectures and parameters. Evaluate your best network on the test set. Save the trained weights of the first fully connected layer in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the different networks to try\n",
    "neural_networks={\n",
    "    '2-layer-32': {\n",
    "        'hidden': [32],\n",
    "        'graph': None,\n",
    "        'train_op': None,\n",
    "    },\n",
    "    '2-layer-64': {\n",
    "        'hidden': [64],\n",
    "        'graph': None,\n",
    "        'train_op': None,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with network: 2-layer-32\n",
      "  Adding hidden layer with 1 neurons\n",
      "  Trainable Variables:\n",
      "    <tf.Variable '2-layer-32-hidden-1/kernel:0' shape=(784, 32) dtype=float32_ref>\n",
      "    <tf.Variable '2-layer-32-hidden-1/bias:0' shape=(32,) dtype=float32_ref>\n",
      "    <tf.Variable '2-layer-32-output/kernel:0' shape=(32, 10) dtype=float32_ref>\n",
      "    <tf.Variable '2-layer-32-output/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Working with network: 2-layer-64\n",
      "  Adding hidden layer with 1 neurons\n",
      "  Trainable Variables:\n",
      "    <tf.Variable '2-layer-64-hidden-1/kernel:0' shape=(784, 64) dtype=float32_ref>\n",
      "    <tf.Variable '2-layer-64-hidden-1/bias:0' shape=(64,) dtype=float32_ref>\n",
      "    <tf.Variable '2-layer-64-output/kernel:0' shape=(64, 10) dtype=float32_ref>\n",
      "    <tf.Variable '2-layer-64-output/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for network_name in neural_networks.keys():\n",
    "    print(\"Working with network:\", network_name)\n",
    "    \n",
    "    # Redefine the graph\n",
    "    neural_networks[network_name]['graph'] = tf.Graph()\n",
    "    \n",
    "    with neural_networks[network_name]['graph'].as_default():\n",
    "        # Create placeholders\n",
    "        X = tf.placeholder(dtype=tf.float32, shape=[None, 784], name='{}-X'.format(network_name))\n",
    "        y = tf.placeholder(dtype=tf.int32, shape=[None], name='{}-y'.format(network_name))\n",
    "\n",
    "        i=1\n",
    "        X_current=X\n",
    "        for shape in neural_networks[network_name]['hidden']:\n",
    "            print('  Adding hidden layer with {} neurons'.format(i))\n",
    "            # Hidden layer with 16 units\n",
    "            hidden = tf.layers.dense(\n",
    "                X_current, shape, activation=tf.nn.relu, # ReLU\n",
    "                kernel_initializer=tf.variance_scaling_initializer(scale=2, seed=0),\n",
    "                bias_initializer=tf.zeros_initializer(),\n",
    "                name='{}-hidden-{}'.format(network_name, i)\n",
    "            )\n",
    "            i+=1\n",
    "            X_current=hidden\n",
    "\n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(\n",
    "            hidden, 10, activation=None, # No activation function\n",
    "            kernel_initializer=tf.variance_scaling_initializer(scale=1, seed=0),\n",
    "            bias_initializer=tf.zeros_initializer(),\n",
    "            name='{}-output'.format(network_name)\n",
    "        )\n",
    "\n",
    "        # Loss fuction: mean cross-entropy\n",
    "        mean_ce = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "\n",
    "        # Gradient descent\n",
    "        lr = tf.placeholder(dtype=tf.float32, name='{}-lr'.format(network_name))\n",
    "        gd = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "\n",
    "        # Minimize cross-entropy\n",
    "        train_op = gd.minimize(mean_ce, name='{}-train_op'.format(network_name))\n",
    "\n",
    "        # Compute predictions and accuracy\n",
    "        predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        is_correct = tf.equal(y, predictions)\n",
    "        accuracy = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32), name='{}-accuracy'.format(network_name))\n",
    "        neural_networks[network_name]['accuracy']=accuracy\n",
    "        \n",
    "        print(\"  Trainable Variables:\")\n",
    "        for v in tf.trainable_variables():\n",
    "            print(\"   \",v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Operation.values of <tf.Operation '2-layer-64-train_op' type=NoOp>>\n",
      "None\n",
      "Epoch 1 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 2 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 3 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 4 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 5 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 6 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 7 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 8 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 9 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 10 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 11 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 12 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 13 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 14 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 15 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 16 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 17 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 18 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 19 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 20 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 21 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 22 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 23 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 24 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 25 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 26 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 27 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 28 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 29 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 30 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 31 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 32 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 33 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 34 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 35 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 36 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 37 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 38 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 39 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 40 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 41 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 42 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 43 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 44 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 45 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 46 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 47 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 48 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 49 - valid: 2.000 train: 3.000 (mean)\n",
      "None\n",
      "Epoch 50 - valid: 2.000 train: 3.000 (mean)\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "valid_acc_values = []\n",
    "\n",
    "network_name='2-layer-64'\n",
    "\n",
    "graph=neural_networks[network_name]['graph']\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Set seed\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Get variables\n",
    "    X=graph.get_tensor_by_name('{}-X:0'.format(network_name))\n",
    "    y=graph.get_tensor_by_name('{}-y:0'.format(network_name))\n",
    "    lr=graph.get_tensor_by_name('{}-lr:0'.format(network_name))\n",
    "    \n",
    "    train_op=graph.get_operation_by_name('{}-train_op'.format(network_name))\n",
    "    accuracy=graph.get_operation_by_name('{}-accuracy'.format(network_name))\n",
    "\n",
    "    print(train_op.values)\n",
    "    \n",
    "    # Train several epochs\n",
    "    for epoch in range(50):\n",
    "        # Accuracy values (train) after each batch\n",
    "        batch_acc = []\n",
    "\n",
    "        # Get batches of data\n",
    "        for X_batch, y_batch in get_batches(X_train_rescaled, y_train, 32):\n",
    "            # Run training and evaluate accuracy\n",
    "            _, acc_value = sess.run([train_op, accuracy], feed_dict={\n",
    "                X: X_batch,\n",
    "                y: y_batch,\n",
    "                lr: 0.001 # Learning rate\n",
    "            })\n",
    "\n",
    "            # Save accuracy (current batch)\n",
    "            batch_acc.append(acc_value)\n",
    "\n",
    "        # Evaluate validation accuracy\n",
    "        valid_acc = sess.run(accuracy, feed_dict={\n",
    "            X: X_valid_rescaled,\n",
    "            y: y_valid\n",
    "        })\n",
    "        valid_acc_values.append(valid_acc)\n",
    "        print(valid_acc)\n",
    "\n",
    "        # Print progress\n",
    "        print('Epoch {} - valid: {:.3f} train: {:.3f} (mean)'.format(\n",
    "            epoch+1,\n",
    "            2, 3\n",
    "            #np.mean(batch_acc)\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'productX:0' refers to a Tensor which does not exist. The operation, 'productX', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-3ffb98e946cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Get variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;34m\"productX:0\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Train several epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3664\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3665\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3666\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3492\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3530\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3531\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'productX:0' refers to a Tensor which does not exist. The operation, 'productX', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "valid_acc_values = []\n",
    "\n",
    "graph=neural_networks['2-layer-32']['graph']\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Set seed\n",
    "    np.random.seed(0)\n",
    "\n",
    "    \n",
    "    # Get variables\n",
    "    X=graph.get_tensor_by_name(  \"productX:0\" )\n",
    "    \n",
    "    # Train several epochs\n",
    "    for epoch in range(50):\n",
    "        # Accuracy values (train) after each batch\n",
    "        batch_acc = []\n",
    "\n",
    "        # Get batches of data\n",
    "        for X_batch, y_batch in get_batches(X_train_rescaled, y_train, 64):\n",
    "            # Run training and evaluate accuracy\n",
    "            _, acc_value = sess.run([train_op, accuracy], feed_dict={\n",
    "                X: X_batch,\n",
    "                y: y_batch,\n",
    "                lr: 0.01 # Learning rate\n",
    "            })\n",
    "\n",
    "            # Save accuracy (current batch)\n",
    "            batch_acc.append(acc_value)\n",
    "\n",
    "        # Evaluate validation accuracy\n",
    "        valid_acc = sess.run(accuracy, feed_dict={\n",
    "            X: X_valid_rescaled,\n",
    "            y: y_valid\n",
    "        })\n",
    "        valid_acc_values.append(valid_acc)\n",
    "\n",
    "        # Print progress\n",
    "        print('Epoch {} - valid: {:.3f} train: {:.3f} (mean)'.format(\n",
    "            epoch+1, valid_acc, np.mean(batch_acc)\n",
    "        ))\n",
    "\n",
    "    # Weights of the hidden and output layers\n",
    "    #weights_hidden = W1.eval()\n",
    "    #weights_output = W2.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Visualize weights\n",
    "\n",
    "> **Exercise**: Plot the weights from the first fully connected layer (the templates) with the `imshow()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X,y data from NPZ\n",
    "\n",
    "Using the function added to *mylib.py* file, it's now easy to grab data and X/y vectors ready to be used for model training and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run content of mylib.py file\n",
    "%run mylib.py\n",
    "\n",
    "# Load data from NPZ file\n",
    "#data=loadNpz()\n",
    "(data, X, y)=loadXy(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further, let's talk a bit about *High Level Features*.\n",
    "\n",
    "Wondering how those high level features are built, I've made some research on the Internet to find out how I could fit my own *Inception v3* high level features using the *small* dataset I have here.\n",
    "\n",
    "As I will build my own Convolutional neural network, I will at the same time grab hish level features of 2048 bytes to be reused with one of the models build in the previous Notebooks.\n",
    "\n",
    "Of course, the result will be extremly poor, I can not race against *Inception V3* fitting process on millions of pictures.\n",
    "\n",
    "Anyway, this is fun to try, so let's do it.\n",
    "\n",
    "    Note: High level feature extractions have been taken from https://www.tutorialspoint.com/how-can-keras-be-used-to-extract-features-from-only-one-layer-of-the-model-using-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Build a Conv Network and fit it\n",
    "\n",
    "\n",
    "### Prepare the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "IMAGE_SIZE=data['IMAGE_SIZE']\n",
    "\n",
    "IMAGE_COLOR_SPACE_DIM=data['IMAGE_COLOR_SPACE_DIM']\n",
    "\n",
    "NB_LABELS=data['IMAGE_NB_LABELS']\n",
    "\n",
    "FEATURE_SIZE=data['FEATURE_SIZE']\n",
    "\n",
    "DATASET_NAME=data['DATASET_NAME']\n",
    "\n",
    "\n",
    "KERAS_INPUT_SHAPE=(IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_COLOR_SPACE_DIM)\n",
    "\n",
    "\n",
    "X_tr=np.float32(data['trainX']['data'])\n",
    "y_tr=data['trainX']['labels']\n",
    "\n",
    "X_te=np.float32(data['test']['data'])\n",
    "y_te=data['test']['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the needed libraries and define model\n",
    "\n",
    "The model used here is taken from different exemples in the course.\n",
    "\n",
    "The most important this to notice is the name of the 2048 Dense layer: *high-level-features*\n",
    "\n",
    "This is from that layer that I will extract my 2048 high level features, to be used aginst a previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16928)             0         \n",
      "_________________________________________________________________\n",
      "high-level-features (Dense)  (None, 2048)              34670592  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 35,997,094\n",
      "Trainable params: 35,997,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "# Convolutional Network\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=5, strides=2,\n",
    "                              activation='relu', input_shape=KERAS_INPUT_SHAPE))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,\n",
    "                              activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=2048, activation='relu', name='high-level-features'))\n",
    "model.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=6, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model\n",
    "\n",
    "optimzer, loss and EarlyStopping function are standard ones already used in previous Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 336 samples, validate on 84 samples\n",
      "Epoch 1/100\n",
      "336/336 [==============================] - 8s 24ms/step - loss: 3.5299 - acc: 0.2679 - val_loss: 2.0457 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 1.6667 - acc: 0.3185 - val_loss: 2.1381 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 1.5249 - acc: 0.4345 - val_loss: 1.9208 - val_acc: 0.1071\n",
      "Epoch 4/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 1.3638 - acc: 0.5119 - val_loss: 1.8421 - val_acc: 0.1071\n",
      "Epoch 5/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 1.1728 - acc: 0.5655 - val_loss: 1.8404 - val_acc: 0.1905\n",
      "Epoch 6/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.9486 - acc: 0.6696 - val_loss: 1.5545 - val_acc: 0.3452\n",
      "Epoch 7/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.6937 - acc: 0.7946 - val_loss: 1.7050 - val_acc: 0.3452\n",
      "Epoch 8/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.4230 - acc: 0.8988 - val_loss: 1.5673 - val_acc: 0.4524\n",
      "Epoch 9/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2715 - acc: 0.9167 - val_loss: 2.0268 - val_acc: 0.3690\n",
      "Epoch 10/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1397 - acc: 0.9613 - val_loss: 2.2311 - val_acc: 0.3214\n",
      "Epoch 11/100\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0563 - acc: 0.9940 - val_loss: 2.6347 - val_acc: 0.3214\n",
      "Epoch 12/100\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.1363 - val_acc: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8deaf62320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adamax(), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
    "\n",
    "# Train model\n",
    "\n",
    "model.fit(X_tr, y_tr, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=1, workers=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "As expected, the score is very bad compared to the *Inception v3* high level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 52.94%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_te, y_te, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "It's now time to save the model in order to use it in the last Notebook of this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model cnn to model-cnn.sav using 'keras.models.save_model' library\n"
     ]
    }
   ],
   "source": [
    "saveModel(model, 'cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, what about high level features ?\n",
    "\n",
    "As explained at the begining of this Notebook, I've decided to build my own high level features while fitting my Conv Network.\n",
    "\n",
    "To do so, I will use the *keras.Model()* method to retrieve layers of my Conv Network, starting from the first one to the one named *high-level-features*\n",
    "\n",
    "    Note: For more details on this, follow the weblink referenced at the begining of this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor = keras.Model(\n",
    "   inputs=model.inputs,\n",
    "   outputs=model.get_layer(name=\"high-level-features\").output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the model now shows a Conv Net with the last layer being a Dense layer of 2048 bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16928)             0         \n",
      "_________________________________________________________________\n",
      "high-level-features (Dense)  (None, 2048)              34670592  \n",
      "=================================================================\n",
      "Total params: 34,682,272\n",
      "Trainable params: 34,682,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to get a *high level feature* array of my dataset, I will simply use the *predict()* method of *keras.Model()* class on my test dataset.\n",
    "\n",
    "I will get a matrix made of 51 entries (number of pictures in the test dataset) and 2048 bytes for each entry, which is the corresponding *high level feature*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = feature_extractor.predict(X_te)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test my own features, let's load one of our previous model (the logistic one for exemple) and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from  model-knn.sav\n",
      "Model loaded using pickle()\n"
     ]
    }
   ],
   "source": [
    "model_to_test='knn'\n",
    "\n",
    "accuracy=loadModel(model_to_test).score(features, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  knn - Accuracy on test dataset using my own features: 15.7%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy*100\n",
    "print(\"  {} - Accuracy on test dataset using my own features: {:.1f}%\\n\".format(model_to_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than 16% accuracy, this is very bad :-)\n",
    "\n",
    "Remember, this model performs 92% score using the *high level features* made from *Inception v3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from  model-knn.sav\n",
      "Model loaded using pickle()\n",
      "Accuracy on test dataset using Inception v3 features: 92.2%\n"
     ]
    }
   ],
   "source": [
    "accuracy=loadModel(model_to_test).score(X['test'], y['test'])\n",
    "print(\"Accuracy on test dataset using Inception v3 features: {:.1f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Using models trained on huge dataset is the key to get the best accuracy for machine learning processes.\n",
    "\n",
    "This has been demonstrated by building my own Convolution Network and compare result against all other models trained from the *Inception V3* high level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to go to our last Notebook to visualize the results taken from the variouis models trained in this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a194ad4",
   "metadata": {},
   "source": [
    "# Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b99257",
   "metadata": {},
   "source": [
    "## Load X,y data from NPZ\n",
    "\n",
    "Using the function added to *mylib.py* file, it's now easy to grab data and X/y vectors ready to be used for model training and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974d5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run content of mylib.py file\n",
    "%run mylib.py\n",
    "\n",
    "# Load data from NPZ file\n",
    "#data=loadNpz()\n",
    "(data, X, y)=loadXy(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c20cfb",
   "metadata": {},
   "source": [
    "https://www.tutorialspoint.com/how-can-keras-be-used-to-extract-features-from-only-one-layer-of-the-model-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772f5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "IMAGE_SIZE=data['IMAGE_SIZE']\n",
    "\n",
    "IMAGE_COLOR_SPACE_DIM=data['IMAGE_COLOR_SPACE_DIM']\n",
    "\n",
    "NB_LABELS=data['IMAGE_NB_LABELS']\n",
    "\n",
    "FEATURE_SIZE=data['FEATURE_SIZE']\n",
    "\n",
    "DATASET_NAME=data['DATASET_NAME']\n",
    "\n",
    "\n",
    "KERAS_INPUT_SHAPE=(IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_COLOR_SPACE_DIM)\n",
    "\n",
    "\n",
    "X_input=data['trainX']['data']\n",
    "\n",
    "X_input=np.float32(X_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c233e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train set\n",
      "Found 280 images belonging to 6 classes.\n",
      "\n",
      "Loading test set\n",
      "Found 50 images belonging to 6 classes.\n",
      "\n",
      "Loading valid set\n",
      "Found 139 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Some constant \n",
    "BATCH_SIZE=32\n",
    "\n",
    "# Create image generators for each dataset\n",
    "image_batches=dict()\n",
    "\n",
    "for name in DATASET_NAME:\n",
    "    print(\"\\nLoading {} set\".format(name))\n",
    "    image_batches[name]=ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        os.path.join('data',name),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54c22bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "# Build placeholder shape from our global constant\n",
    "PLACEHOLDER_SHAPE=(None, IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_COLOR_SPACE_DIM)\n",
    "\n",
    "FEATURE_SIZE=2048\n",
    "\n",
    "# Create graph\n",
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Convolutional Network\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=5, strides=2,\n",
    "                                  activation='relu', input_shape=KERAS_INPUT_SHAPE))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=3))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,\n",
    "                                  activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten(name='test'))\n",
    "    model.add(keras.layers.Dense(units=2048, activation='relu', name='test2'))\n",
    "    model.add(keras.layers.Dense(units=6, activation='softmax', name='test3'))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    feature_extractor = keras.Model(\n",
    "       inputs=model.inputs,\n",
    "       outputs=model.get_layer(name=\"test2\").output,\n",
    "    )\n",
    "    \n",
    "    # Create input placeholder\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=PLACEHOLDER_SHAPE)\n",
    "\n",
    "    # A node with the features\n",
    "    imgs_features = feature_extractor(X_input)\n",
    "\n",
    "    # Collect initializers\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "\n",
    "img_graph.finalize() # Good practice: make the graph \"read-only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484ed3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test dataset, total number of batches: 2\n",
      "  batch number 0\n",
      "  batch number 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dict_new=dict()\n",
    "\n",
    "# Create a session\n",
    "sess = tf.Session(graph=img_graph)\n",
    "\n",
    "# Initialize it\n",
    "sess.run(init_op)\n",
    "\n",
    "DATASET_NAME=['test']\n",
    "\n",
    "# For each set\n",
    "for name in DATASET_NAME:\n",
    "    print('Processing {} dataset, total number of batches: {}'.format(name, len(image_batches[name])))\n",
    "    \n",
    "    # Initialize new dict for this new dataset name\n",
    "    data_dict_new[name]=dict()\n",
    "    \n",
    "    # Add filenames to data_dict\n",
    "    data_dict_new[name]['filenames']=image_batches[name].filenames\n",
    "    \n",
    "    # Add label id of each image\n",
    "    data_dict_new[name]['labels']=image_batches[name].labels\n",
    "\n",
    "    \n",
    "    # Initialize empty array for data and feature var\n",
    "    # Those var will be used to accumulate data between for loops\n",
    "    # They are initialized to empty array with the correct shape\n",
    "    data=np.empty((0, IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_COLOR_SPACE_DIM))\n",
    "    features=np.empty((0, FEATURE_SIZE))\n",
    " \n",
    "    # For each batch of each set\n",
    "    for batch in range(0, len(image_batches[name])):\n",
    "        print('  batch number {}'.format(batch))\n",
    "        \n",
    "        # Append new data batch to previous data batches\n",
    "        data=np.append(data, image_batches[name][batch][0], axis=0)\n",
    "\n",
    "        # Get high-level features from data\n",
    "        features=np.append(features, sess.run(imgs_features, feed_dict={input_imgs: image_batches[name][batch][0]}), axis=0)\n",
    "\n",
    "\n",
    "        # print(features.shape)\n",
    "        # train_features.extend(features)\n",
    "        \n",
    "    # Store data in global data_dict\n",
    "    data_dict_new[name]['data']=data\n",
    "    \n",
    "    # Store features in global dict\n",
    "    data_dict_new[name]['features']=features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bca02938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 2048)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_new['test']['features'].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ce0f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 148, 148, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "test (Flatten)               (None, 16928)             0         \n",
      "_________________________________________________________________\n",
      "test2 (Dense)                (None, 2048)              34670592  \n",
      "_________________________________________________________________\n",
      "test3 (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 34,702,762\n",
      "Trainable params: 34,702,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convolutional Network\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=5, strides=2,\n",
    "                                  activation='relu', input_shape=KERAS_INPUT_SHAPE))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=3))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,\n",
    "                                  activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten(name='test'))\n",
    "    model.add(keras.layers.Dense(units=2048, activation='relu', name='test2'))\n",
    "    model.add(keras.layers.Dense(units=10, activation='softmax', name='test3'))\n",
    "\n",
    "\n",
    "    \n",
    "    model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bdad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

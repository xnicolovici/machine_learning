{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X,y data from NPZ\n",
    "\n",
    "Using the function added to *mylib.py* file, it's now easy to grab data and X/y vectors ready to be used for model training and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'train' set\n",
      "  loading  data\n",
      "     shape: (281, 299, 299, 3) - dtype: float64\n",
      "  loading  features\n",
      "     shape: (281, 2048) - dtype: float64\n",
      "  loading  filenames\n",
      "     shape: (281,) - dtype: <U46\n",
      "  loading  labels\n",
      "     shape: (281,) - dtype: int32\n",
      "\n",
      "\n",
      "Loading 'test' set\n",
      "  loading  data\n",
      "     shape: (51, 299, 299, 3) - dtype: float64\n",
      "  loading  features\n",
      "     shape: (51, 2048) - dtype: float64\n",
      "  loading  filenames\n",
      "     shape: (51,) - dtype: <U50\n",
      "  loading  labels\n",
      "     shape: (51,) - dtype: int32\n",
      "\n",
      "\n",
      "Loading 'valid' set\n",
      "  loading  data\n",
      "     shape: (139, 299, 299, 3) - dtype: float64\n",
      "  loading  features\n",
      "     shape: (139, 2048) - dtype: float64\n",
      "  loading  filenames\n",
      "     shape: (139,) - dtype: <U30\n",
      "  loading  labels\n",
      "     shape: (139,) - dtype: int32\n",
      "\n",
      "\n",
      "building 'trainX' set\n",
      "  building  data\n",
      "     shape: (420, 299, 299, 3) - dtype: float64\n",
      "  building  features\n",
      "     shape: (420, 2048) - dtype: float64\n",
      "  building  filenames\n",
      "     shape: (420,) - dtype: <U46\n",
      "  building  labels\n",
      "     shape: (420,) - dtype: int32\n",
      "\n",
      "\n",
      "X['train'] shape: (281, 2048)\n",
      "y['train'] shape: (281, 2048)\n",
      "X['test'] shape: (51, 2048)\n",
      "y['test'] shape: (51, 2048)\n",
      "X['valid'] shape: (139, 2048)\n",
      "y['valid'] shape: (139, 2048)\n",
      "X['trainX'] shape: (420, 2048)\n",
      "y['trainX'] shape: (420, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Run content of mylib.py file\n",
    "%run mylib.py\n",
    "\n",
    "# Load data from NPZ file\n",
    "#data=loadNpz()\n",
    "(data, X, y)=loadXy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate without any hyperparameters tuning\n",
    "\n",
    "To do so, I will simply create a LogisticRegression estimator object using default parameters, fit it, and evaluate it agains the *test* dataset.\n",
    "\n",
    "> Note: I've explicitly set some hyperparameters to avoid warnings about default values that will be changed in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score : 96.1%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Cross Validation K-Fold dimension\n",
    "CV=5\n",
    "\n",
    "lr=LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=10000)\n",
    "\n",
    "grid_param={}\n",
    "\n",
    "grid_lr=GridSearchCV(lr, grid_param, cv=CV, refit=True, return_train_score=True, verbose=True, n_jobs=-1, iid=True)\n",
    "\n",
    "grid_lr.fit(X['trainX'], y['trainX'])\n",
    "\n",
    "accuracy_lr=grid_lr.score(X['test'], y['test'])*100\n",
    "\n",
    "print(\"LogisticRegression score : {:.1f}%\".format(accuracy_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'multi_class': ['ovr', 'multinomial'], 'C': array([1.00000e-04, 7.74264e-04, 5.99484e-03, 4.64159e-02, 3.59381e-01,\n",
       "       2.78256e+00, 2.15443e+01, 1.66810e+02, 1.29155e+03, 1.00000e+04]), 'solver': ['sag', 'saga', 'lbfgs']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr=LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=10000)\n",
    "\n",
    "grid_param={\n",
    "    'multi_class': ['ovr','multinomial'],\n",
    "    'C': np.logspace(-4, 4, num=10),\n",
    "    'solver': ['sag', 'saga', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_lr=GridSearchCV(lr, grid_param, cv=CV, refit=True, return_train_score=True, verbose=True, n_jobs=-1, iid=True)\n",
    "\n",
    "grid_lr.fit(X['trainX'], y['trainX'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sag</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>saga</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sag</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>2.78256</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_solver param_multi_class   param_C  mean_test_score  std_test_score  \\\n",
       "27          sag       multinomial  0.359381         0.940476        0.011882   \n",
       "28         saga       multinomial  0.359381         0.940476        0.011882   \n",
       "24          sag               ovr  0.359381         0.935714        0.011110   \n",
       "35        lbfgs       multinomial   2.78256         0.935714        0.011312   \n",
       "26        lbfgs               ovr  0.359381         0.935714        0.011110   \n",
       "\n",
       "    mean_train_score  \n",
       "27               1.0  \n",
       "28               1.0  \n",
       "24               1.0  \n",
       "35               1.0  \n",
       "26               1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns=['param_solver', 'param_multi_class', 'param_C', 'mean_test_score', 'std_test_score', 'mean_train_score']\n",
    "pd.DataFrame(grid_lr.cv_results_).sort_values('mean_test_score', ascending=False)[columns].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score : 96.1%\n"
     ]
    }
   ],
   "source": [
    "best_lr=grid_lr.best_estimator_\n",
    "\n",
    "best_accuracy_lr=best_lr.score(X['test'], y['test'])*100\n",
    "\n",
    "print(\"LogisticRegression score : {:.1f}%\".format(best_accuracy_lr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model logistic to model-logistic.sav\n"
     ]
    }
   ],
   "source": [
    "saveModel(best_lr, 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poulet shahi korma\n",
    "agneau biriani\n",
    "agneau tikka masala\n",
    "\n",
    "riz basmati\n",
    "riz ail\n",
    "\n",
    "3 x nan fromage\n",
    "\n",
    "\n",
    "Dal Tarka\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Murg e shalimar\n",
    "poulet vindaloo\n",
    "Thalis nauratan\n",
    "\n",
    "3 nan fromage\n",
    "\n",
    "riz nature\n",
    "riz aux petits pois\n",
    "\n",
    "panchmel daal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X,y data from NPZ\n",
    "\n",
    "Using the function added to *mylib.py* file, it's now easy to grab data and X/y vectors ready to be used for model training and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'train' set\n",
      "  loading  data\n",
      "     shape: (281, 299, 299, 3) - dtype: float64\n",
      "  loading  features\n",
      "     shape: (281, 2048) - dtype: float64\n",
      "  loading  filenames\n",
      "     shape: (281,) - dtype: <U46\n",
      "  loading  labels\n",
      "     shape: (281,) - dtype: int32\n",
      "\n",
      "\n",
      "Loading 'test' set\n",
      "  loading  data\n",
      "     shape: (51, 299, 299, 3) - dtype: float64\n",
      "  loading  features\n",
      "     shape: (51, 2048) - dtype: float64\n",
      "  loading  filenames\n",
      "     shape: (51,) - dtype: <U50\n",
      "  loading  labels\n",
      "     shape: (51,) - dtype: int32\n",
      "\n",
      "\n",
      "Loading 'valid' set\n",
      "  loading  data\n",
      "     shape: (139, 299, 299, 3) - dtype: float64\n",
      "  loading  features\n",
      "     shape: (139, 2048) - dtype: float64\n",
      "  loading  filenames\n",
      "     shape: (139,) - dtype: <U30\n",
      "  loading  labels\n",
      "     shape: (139,) - dtype: int32\n",
      "\n",
      "\n",
      "building 'trainX' set\n",
      "  building  data\n",
      "     shape: (420, 299, 299, 3) - dtype: float64\n",
      "  building  features\n",
      "     shape: (420, 2048) - dtype: float64\n",
      "  building  filenames\n",
      "     shape: (420,) - dtype: <U46\n",
      "  building  labels\n",
      "     shape: (420,) - dtype: int32\n",
      "\n",
      "\n",
      "X['train'] shape: (281, 2048)\n",
      "y['train'] shape: (281, 2048)\n",
      "X['test'] shape: (51, 2048)\n",
      "y['test'] shape: (51, 2048)\n",
      "X['valid'] shape: (139, 2048)\n",
      "y['valid'] shape: (139, 2048)\n",
      "X['trainX'] shape: (420, 2048)\n",
      "y['trainX'] shape: (420, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Run content of mylib.py file\n",
    "%run mylib.py\n",
    "\n",
    "# Load data from NPZ file\n",
    "#data=loadNpz()\n",
    "(data, X, y)=loadXy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four different decision trees\n",
    "\n",
    "In that Notebook, I will try four different type of decision trees:\n",
    "\n",
    "* DecisionTreeClassifier\n",
    "* RandomForestClassifier\n",
    "* LinearSVC, which is the same as SVM(kernel='linear')\n",
    "* SVM(kernel='rbf')\n",
    "\n",
    "For each of them, I'll do a grid search to fine tune the hyperparameters. I'll also save the model with the best hyperparameters on disk, in order to use them at the end of this project.\n",
    "\n",
    "In the next cell, I will import needed liraries and define some constant I will use across the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# cv parameter of the GridSearchCV object\n",
    "CV=5\n",
    "\n",
    "# max tree depth to us in model\n",
    "MAX_DEPTH=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_dt__criterion</th>\n",
       "      <th>param_dt__max_depth</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.035642</td>\n",
       "      <td>0.993463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.041360</td>\n",
       "      <td>0.989868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.024973</td>\n",
       "      <td>0.954749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.873810</td>\n",
       "      <td>0.036461</td>\n",
       "      <td>0.990469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>gini</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.996416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         param_scaler param_dt__criterion  \\\n",
       "76                                               None             entropy   \n",
       "78                                               None             entropy   \n",
       "23  StandardScaler(copy=True, with_mean=True, with...                gini   \n",
       "39  StandardScaler(copy=True, with_mean=True, with...                gini   \n",
       "47  StandardScaler(copy=True, with_mean=True, with...                gini   \n",
       "\n",
       "   param_dt__max_depth param_pca__n_components  mean_test_score  \\\n",
       "76                   7                      76         0.883333   \n",
       "78                   7                      16         0.880952   \n",
       "23                   6                      16         0.880952   \n",
       "39                   8                      16         0.873810   \n",
       "47                   9                      16         0.871429   \n",
       "\n",
       "    std_test_score  mean_train_score  \n",
       "76        0.035642          0.993463  \n",
       "78        0.041360          0.989868  \n",
       "23        0.024973          0.954749  \n",
       "39        0.036461          0.990469  \n",
       "47        0.026560          0.996416  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create decision tree\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion='gini', max_depth=MAX_DEPTH, random_state=0)\n",
    "\n",
    "# Create the pipeline and fit it to training data\n",
    "dt_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=None)),\n",
    "    ('dt', dt)\n",
    "    \n",
    "])\n",
    "\n",
    "# Here are the different parameters I will vary\n",
    "dt_grid_param={\n",
    "    'scaler': [None, StandardScaler()],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [3, 5, 6, 7, 8, 9],\n",
    "    'pca__n_components': [None, 128, 76, 16]\n",
    "}\n",
    "\n",
    "# Build the GridSearchCV object using versbose and parallel execution options\n",
    "grid_dt=GridSearchCV(dt_pipe, dt_grid_param, cv=CV, refit=True, return_train_score=True, verbose=True, n_jobs=-1, iid=True)\n",
    "\n",
    "\n",
    "# grid_cv.get_params().keys()\n",
    "# Fit the model\n",
    "grid_dt.fit(X['trainX'], y['trainX'])\n",
    "\n",
    "\n",
    "# Display top 5 best test score\n",
    "columns=[\n",
    "    'param_scaler', 'param_dt__criterion', 'param_dt__max_depth', 'param_pca__n_components', 'mean_test_score', 'std_test_score', 'mean_train_score'\n",
    "]\n",
    "pd.DataFrame(grid_dt.cv_results_).sort_values('mean_test_score', ascending=False)[columns].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Export decision tree\n",
    "dot_data = export_graphviz(\n",
    "    dt, out_file=None,\n",
    "    feature_names=features.columns, class_names=['died', 'survived'],\n",
    "    filled=True, rounded=True, proportion=True   \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

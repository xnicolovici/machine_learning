{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usefull stuff for the upcoming project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some basic lib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline preprocessor\n",
    "\n",
    "First seen in *04. Logistic Regression / 07. Exercise - Heart disease diagnosis / 05 Solution - Heart disease.ipynb*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# One-hot encoding\n",
    "onehot_columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "\n",
    "# Numerical features\n",
    "other_columns = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), onehot_columns),\n",
    "    ('other', 'passthrough', other_columns)\n",
    "])\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# k-NN estimator\n",
    "knn_estimator = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()), # Standardize features before k-NN\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get proportion of different values in a np.Series\n",
    "\n",
    "Using the pandas.value_counts() function with *nomralize* parameter set to *True* displays the percentage of each values instead of simply the number of occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[1,1,1,2,2,2,3,4,5,5]\n",
    "\n",
    "# Proportion of features in each class\n",
    "pd.value_counts(y, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a decision tree\n",
    "\n",
    "You can find how to do that in *05. Decision trees and SVMs/02. Decision trees/Learn.ipynb*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "\n",
    "# Export decision tree\n",
    "dot_data = export_graphviz(\n",
    "    dt, out_file=None,\n",
    "    feature_names=encoded_df.drop('survived',axis=1).columns, class_names=['died', 'survived'],\n",
    "    filled=True, rounded=True, proportion=True   \n",
    ")\n",
    "\n",
    "import graphviz\n",
    "\n",
    "# Display decision tree\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make cross tab between two columns of an pandas dataframe\n",
    "\n",
    "You can find how to do that in *05. Decision trees and SVMs/02. Decision trees/Learn.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross tabulation of sex and survived\n",
    "crosstab = pd.crosstab(\n",
    "    index=data_df.sex,\n",
    "    columns=data_df.survived,\n",
    "    normalize='index' # Normalize by sex\n",
    ")\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not forget to scale values !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X = scale(data_df.drop('y', axis=1).values) # Rescale input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some default values for various classifiers \n",
    "> * Logistic regression\n",
    "> * SVM with linear kernel\n",
    "> * *k*-NN\n",
    "> * Decision tree\n",
    "> * Random forest\n",
    "> * SVM with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Logistic regression\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# SVM with linear kernel\n",
    "linear_svc = LinearSVC(random_state=0)\n",
    "\n",
    "# k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "# Decision tree\n",
    "dt = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0)\n",
    "\n",
    "# SVM with RBF kernel\n",
    "rbf_svc = SVC(kernel='rbf', C=10, gamma=1, random_state=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart disease diagnosis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Evaluate \"most-frequent\" baseline\n",
    "\n",
    "> **Exercise**: Load and split the `heart-disease.csv` data into 70-30 train/test sets - make sure to keep the same proportion of classes by setting `stratify`. Evaluate the accuracy of the \"most-frequent\" baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    0   0       145   233    0        0      150      1      2.3      0   \n",
       "1   67    0   1       160   286    1        0      108      0      1.5      1   \n",
       "2   67    0   1       120   229    1        0      129      0      2.6      1   \n",
       "3   37    0   2       130   250    1        1      187      1      3.5      0   \n",
       "4   41    1   3       130   204    1        0      172      1      1.4      2   \n",
       "\n",
       "   ca  thal  disease  \n",
       "0   0     0  absence  \n",
       "1   3     1   likely  \n",
       "2   2     2   likely  \n",
       "3   0     1  absence  \n",
       "4   0     1  absence  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv(os.path.join('data','heart-disease.csv'))\n",
    "df.sex=df.sex.map({'male':0, 'female':1})\n",
    "df.cp=df.cp.map({'typical angina':0, 'asymptomatic':1, 'non-anginal pain':2, 'atypical angina':3})\n",
    "df.restecg=df.restecg.map({'ventricular hypertrophy':0, 'normal':1, 'ST-T wave':2})\n",
    "df.fbs=df.fbs.map({'yes':0, 'no':1})\n",
    "df.exang=df.exang.map({'yes':0, 'no':1})\n",
    "df.slope=df.slope.map({'downsloping':0, 'flat':1, 'upsloping':2})\n",
    "df.thal=df.thal.map({'fixed defect':0, 'normal':1, 'reversable defect':2})\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.85%\n"
     ]
    }
   ],
   "source": [
    "X=df.drop('disease',axis=1).values\n",
    "y=df.disease.values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te, = train_test_split(X,y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# Evaluate 'most-frequent' baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create the dummy classifier\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit it\n",
    "dummy.fit(X_tr, y_tr)\n",
    "\n",
    "# Compute test accuracy\n",
    "accuracy = dummy.score(X_te, y_te)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Evaluate k-NN baseline\n",
    "---\n",
    "\n",
    "> **Exercise**: Tune a k-NN classifier using grid search with **stratified 10-fold** cross-validation\n",
    "> * Number of neighbors k\n",
    "> * Distance metric - $L_{1}$ or $L_{2}$\n",
    "> * Weighting strategy - uniform or by distance\n",
    ">\n",
    "> Refit the best estimator on the whole train set and report the test accuracy.\n",
    "\n",
    "Data set documentation: http://archive.ics.uci.edu/ml/datasets/heart+Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:    1.6s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_knn__weights</th>\n",
       "      <th>param_knn__p</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.051978</td>\n",
       "      <td>0.680813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.693918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.665094</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.665094</td>\n",
       "      <td>0.041836</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.665094</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        param_scaler param_knn__weights param_knn__p param_knn__n_neighbors  \\\n",
       "49  StandardScaler()            uniform            1                     30   \n",
       "33  StandardScaler()            uniform            1                     15   \n",
       "35  StandardScaler()           distance            1                     15   \n",
       "59  StandardScaler()           distance            1                     50   \n",
       "51  StandardScaler()           distance            1                     30   \n",
       "\n",
       "    mean_test_score  std_test_score  mean_train_score  \n",
       "49         0.674528        0.051978          0.680813  \n",
       "33         0.669811        0.046160          0.693918  \n",
       "35         0.665094        0.054266          1.000000  \n",
       "59         0.665094        0.041836          1.000000  \n",
       "51         0.665094        0.036069          1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn=Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Create k-fold object\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "grid_param={\n",
    "    'scaler': [None, StandardScaler()],\n",
    "    'knn__n_neighbors': [1,2,5,10,15,20, 30, 50],\n",
    "    'knn__weights': ['uniform','distance'],\n",
    "    'knn__p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_cv=GridSearchCV(knn, grid_param, cv=10, refit=True, return_train_score=True, verbose=True, n_jobs=-1, iid=True)\n",
    "\n",
    "grid_cv.fit(X_tr, y_tr)\n",
    "\n",
    "columns=['param_scaler', 'param_knn__weights', 'param_knn__p', 'param_knn__n_neighbors', 'mean_test_score', 'std_test_score', 'mean_train_score']\n",
    "pd.DataFrame(grid_cv.cv_results_).sort_values('mean_test_score', ascending=False)[columns].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Logistic regression\n",
    "---\n",
    "\n",
    "> **Exercise**: Same with a logistic regression\n",
    "> * Try both OvR and softmax\n",
    "> * tune C\n",
    ">\n",
    "> Which estimator would you use in practice? k-NN or logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 880 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:   24.2s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_knn__solver</th>\n",
       "      <th>param_knn__multi_class</th>\n",
       "      <th>param_knn__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>sag</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.081538</td>\n",
       "      <td>0.735842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.081538</td>\n",
       "      <td>0.735842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>saga</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.081538</td>\n",
       "      <td>0.735842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.072415</td>\n",
       "      <td>0.744737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>saga</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>166.81</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.072415</td>\n",
       "      <td>0.744737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         param_scaler param_knn__solver param_knn__multi_class param_knn__C  \\\n",
       "49   StandardScaler()               sag                    ovr     0.359381   \n",
       "53   StandardScaler()             lbfgs                    ovr     0.359381   \n",
       "51   StandardScaler()              saga                    ovr     0.359381   \n",
       "119  StandardScaler()             lbfgs            multinomial        10000   \n",
       "93   StandardScaler()              saga            multinomial       166.81   \n",
       "\n",
       "     mean_test_score  std_test_score  mean_train_score  \n",
       "49          0.679245        0.081538          0.735842  \n",
       "53          0.679245        0.081538          0.735842  \n",
       "51          0.679245        0.081538          0.735842  \n",
       "119         0.674528        0.072415          0.744737  \n",
       "93          0.674528        0.072415          0.744737  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "knn=Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=10000))\n",
    "])\n",
    "\n",
    "# Create k-fold object\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "grid_param={\n",
    "    'scaler': [None, StandardScaler()],\n",
    "    'knn__multi_class': ['ovr','multinomial'],\n",
    "    'knn__C': np.logspace(-4, 4, num=10),\n",
    "    'knn__solver': ['sag', 'saga', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_cv=GridSearchCV(knn, grid_param, cv=10, refit=True, return_train_score=True, verbose=True, n_jobs=-1, iid=True)\n",
    "\n",
    "grid_cv.fit(X_tr, y_tr)\n",
    "\n",
    "columns=['param_scaler', 'param_knn__solver', 'param_knn__multi_class', 'param_knn__C', 'mean_test_score', 'std_test_score', 'mean_train_score']\n",
    "pd.DataFrame(grid_cv.cv_results_).sort_values('mean_test_score', ascending=False)[columns].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

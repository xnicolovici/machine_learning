{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words representation\n",
    "---\n",
    "\n",
    "Goal: Represent texts as a vector of numbers for our ML tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cannot use X: ML models work with numerical features!\n",
    "X = [\n",
    "    \"Scikit-learn makes ML easy, easy as 123\", \n",
    "    \"Learning TensorFlow for deep learning\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: Create a feature for each word with the number of times the word appears as its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Scikit-learn provides a vectorizer transformer for that\n",
    "vect = CountVectorizer()\n",
    "X_encoded = vect.fit_transform(X);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"scikit\" with index 9\n",
      "\"learn\" with index 5\n",
      "\"makes\" with index 7\n",
      "\"ml\" with index 8\n",
      "\"easy\" with index 3\n",
      "\"as\" with index 1\n",
      "\"123\" with index 0\n",
      "\"learning\" with index 6\n",
      "\"tensorflow\" with index 10\n",
      "\"for\" with index 4\n",
      "\"deep\" with index 2\n"
     ]
    }
   ],
   "source": [
    "# Print vocabulary (the features) with their column index in the feature matrix\n",
    "for word, index in vect.vocabulary_.items():\n",
    "    print('\"{}\" with index {}'.format(word, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input size\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In practice, this approach usually leads to a large number of features (words) and only a few non-zero values per entry. For this reason, Scikit-learn stores the data as a \"sparse matrix\" that only stores non-zero values which is more memory efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-learn uses sparse matrices instead of Numpy arrays\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can always get back the data as Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 2, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "* `X_encoded[0, 3]` is 2 because \"easy\" (with index 3) appears twice in the first entry\n",
    "* `X_encoded[1, 6]` is 2 because \"learning\" with index 6 appears twice in the second entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concrete use case - Sentiment analysis\n",
    "---\n",
    "\n",
    "Task: Classify movie reviews as being `positive` or `negative` about their movie. This is a binary classification task with text input.\n",
    "\n",
    "Download the `Large Movie Review Dataset v1.0 ` data from https://ai.stanford.edu/~amaas/data/sentiment/ and extract it in a `aclImdb` folder next to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import os\n",
    "\n",
    "# Train set\n",
    "train_data = load_files(os.path.join('aclImdb', 'train'), categories=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First review\n",
    "train_data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes\n",
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target[0] # \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 25000\n",
      "Vocabulary size: 74849\n",
      "Input shape: (25000, 74849)\n",
      "Target shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Create X, y arrays\n",
    "vect = CountVectorizer()\n",
    "y = train_data.target\n",
    "X = train_data.data\n",
    "X_encoded = vect.fit_transform(X)\n",
    "\n",
    "# Vocabulary and input\n",
    "print('Training size:', len(train_data.data))\n",
    "print('Vocabulary size:', len(vect.vocabulary_))\n",
    "print('Input shape:', X_encoded.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   43.3s remaining:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   54.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Use logistic regression to classify reviews\n",
    "grid_cv = GridSearchCV(\n",
    "    estimator=LogisticRegression(solver='liblinear'),\n",
    "    param_grid={\n",
    "        'C': [0.1, 1, 10]\n",
    "    },\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_cv.fit(X_encoded, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.88524</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.97990</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.99924</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.87032</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C  mean_test_score  std_test_score  mean_train_score  std_train_score\n",
       "0     0.1          0.88524        0.001181           0.97990         0.000129\n",
       "1       1          0.87604        0.001177           0.99924         0.000057\n",
       "2      10          0.87032        0.001643           1.00000         0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "cv_results = pd.DataFrame(grid_cv.cv_results_)\n",
    "cols = ['param_C', 'mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']\n",
    "cv_results[cols].sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Probably the worst Dolph film ever. There's nothing you'd want or expect here. Don't waste your time. Dolph plays a miserable cop with no interests in life. His brother gets killed and Dolph tries to figure things out. The character is just plain stupid and stumbles around aimlessly. Pointless.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.predict(X_encoded[10])\n",
    "X[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants\n",
    "---\n",
    "\n",
    "There are also slightly more sophisticated methods like TD-IDF which normalizes counts by popularity of the word - the idea is that words that appear in many entries are less relevant to solve our task. A common example are stopwords like \"the\", \"is\", \"a\" but common words might also be specific to our data set ex. \"movie\", \"actor\" are common words in our case and irrelevant to classify the review as positive or negative.\n",
    "\n",
    "In addition to logistic regressions, the Naive Bayes classifier is another baseline to evaluate when working with texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a pipeline this time\n",
    "pipe = Pipeline([\n",
    "    ('vect', None),\n",
    "    ('clf', None)\n",
    "])\n",
    "\n",
    "# Try with simple counts and TF-IDF / Logistic regressions and Naive Bayes\n",
    "grid_cv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid={\n",
    "        'vect': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'clf': [LogisticRegression(solver='liblinear'), MultinomialNB()]\n",
    "    },\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "grid_cv.fit(X, y)\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "cv_results = pd.DataFrame({\n",
    "    'clf': [type(clf).__name__ for clf in grid_cv.cv_results_['param_clf']],\n",
    "    'vect': [type(clf).__name__ for clf in grid_cv.cv_results_['param_vect']],\n",
    "    'mean_test_score': grid_cv.cv_results_['mean_test_score'],\n",
    "    'std_test_score': grid_cv.cv_results_['std_test_score'],\n",
    "    'mean_train_score': grid_cv.cv_results_['mean_train_score'],\n",
    "    'std_train_score': grid_cv.cv_results_['std_train_score']\n",
    "})\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final test evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_files(os.path.join('aclImdb', 'test'), categories=['pos', 'neg'])\n",
    "grid_cv.score(test_data.data, test_data.target) # Score best estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional ressources\n",
    "---\n",
    "\n",
    "Scikit-learn provides many options for vectorizers, make sure to check the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) and [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) documentations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
